{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install q keras==2.3.1"
      ],
      "metadata": {
        "id": "CoJmJi-hhKOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install talos"
      ],
      "metadata": {
        "id": "a6m8ZjgJhygh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.layers import Input, Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras import regularizers\n",
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
        "from tensorflow.python.keras.optimizer_v2.rmsprop import RMSprop\n",
        "from tensorflow.python.keras.optimizer_v2.nadam import Nadam\n",
        "from tensorflow.python.keras.optimizer_v2.adamax import Adamax"
      ],
      "metadata": {
        "id": "leBq31gNJQ8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import talos library (after install keras and talos)\n",
        "import talos as ta\n",
        "from talos.utils import lr_normalizer"
      ],
      "metadata": {
        "id": "4DHyVk8vE-bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O40MvlXKKvDW",
        "outputId": "1148e111-6a92-433a-d34c-82536aeb481f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Bank Customer Churn Prediction.csv')\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6UbKM_gvK3DR",
        "outputId": "de6d70d6-7996-455c-faef-41c609684228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customer_id  credit_score country  gender  age  tenure    balance  \\\n",
              "0     15634602           619  France  Female   42       2       0.00   \n",
              "1     15647311           608   Spain  Female   41       1   83807.86   \n",
              "2     15619304           502  France  Female   42       8  159660.80   \n",
              "3     15701354           699  France  Female   39       1       0.00   \n",
              "4     15737888           850   Spain  Female   43       2  125510.82   \n",
              "\n",
              "   products_number  credit_card  active_member  estimated_salary  churn  \n",
              "0                1            1              1         101348.88      1  \n",
              "1                1            0              1         112542.58      0  \n",
              "2                3            1              0         113931.57      1  \n",
              "3                2            0              0          93826.63      0  \n",
              "4                1            1              1          79084.10      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afcf0058-c326-4d54-bb2b-9a930baa10c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15634602</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15647311</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15619304</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15701354</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15737888</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afcf0058-c326-4d54-bb2b-9a930baa10c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afcf0058-c326-4d54-bb2b-9a930baa10c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afcf0058-c326-4d54-bb2b-9a930baa10c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32KoW7WsMOtg",
        "outputId": "10aa158a-79a1-4f11-8fd0-242b7e7a22e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id         10000\n",
              "credit_score          460\n",
              "country                 3\n",
              "gender                  2\n",
              "age                    70\n",
              "tenure                 11\n",
              "balance              6382\n",
              "products_number         4\n",
              "credit_card             2\n",
              "active_member           2\n",
              "estimated_salary     9999\n",
              "churn                   2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['customer_id'], axis = 1)\n",
        "continuous_vars = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']\n",
        "categorical_vars = ['country', 'gender', 'credit_card', 'active_member']\n",
        "df = df[['churn'] + continuous_vars + categorical_vars]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Jjp28g6-MQcl",
        "outputId": "28d0a496-a9ea-47b8-8d33-9389ab489efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   churn  credit_score  age  tenure    balance  products_number  \\\n",
              "0      1           619   42       2       0.00                1   \n",
              "1      0           608   41       1   83807.86                1   \n",
              "2      1           502   42       8  159660.80                3   \n",
              "3      0           699   39       1       0.00                2   \n",
              "4      0           850   43       2  125510.82                1   \n",
              "\n",
              "   estimated_salary country  gender  credit_card  active_member  \n",
              "0         101348.88  France  Female            1              1  \n",
              "1         112542.58   Spain  Female            0              1  \n",
              "2         113931.57  France  Female            1              0  \n",
              "3          93826.63  France  Female            0              0  \n",
              "4          79084.10   Spain  Female            1              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cca4e44d-dd35-42f1-a32f-cf8c934cb872\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>churn</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cca4e44d-dd35-42f1-a32f-cf8c934cb872')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cca4e44d-dd35-42f1-a32f-cf8c934cb872 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cca4e44d-dd35-42f1-a32f-cf8c934cb872');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing values of column credit_card and active_member from 0 to -1 so that they will influence negatively to the model instead of no effect.\n",
        "df.loc[df.credit_card == 0, 'credit_card'] = -1\n",
        "df.loc[df.active_member == 0, 'active_member'] = -1\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jXB1V7x-MSGV",
        "outputId": "3641f3df-4c44-4a13-aff9-084e049a9e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   churn  credit_score  age  tenure    balance  products_number  \\\n",
              "0      1           619   42       2       0.00                1   \n",
              "1      0           608   41       1   83807.86                1   \n",
              "2      1           502   42       8  159660.80                3   \n",
              "3      0           699   39       1       0.00                2   \n",
              "4      0           850   43       2  125510.82                1   \n",
              "\n",
              "   estimated_salary country  gender  credit_card  active_member  \n",
              "0         101348.88  France  Female            1              1  \n",
              "1         112542.58   Spain  Female           -1              1  \n",
              "2         113931.57  France  Female            1             -1  \n",
              "3          93826.63  France  Female           -1             -1  \n",
              "4          79084.10   Spain  Female            1              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35dedbf9-7c4a-4270-8a11-b1a1a3fbe6cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>churn</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35dedbf9-7c4a-4270-8a11-b1a1a3fbe6cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35dedbf9-7c4a-4270-8a11-b1a1a3fbe6cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35dedbf9-7c4a-4270-8a11-b1a1a3fbe6cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns = ['country', 'gender'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BmeksF8-MTcO",
        "outputId": "24ba3885-fc4f-47e2-ee4f-4da8e3122d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   churn  credit_score  age  tenure    balance  products_number  \\\n",
              "0      1           619   42       2       0.00                1   \n",
              "1      0           608   41       1   83807.86                1   \n",
              "2      1           502   42       8  159660.80                3   \n",
              "3      0           699   39       1       0.00                2   \n",
              "4      0           850   43       2  125510.82                1   \n",
              "\n",
              "   estimated_salary  credit_card  active_member  country_France  \\\n",
              "0         101348.88            1              1               1   \n",
              "1         112542.58           -1              1               0   \n",
              "2         113931.57            1             -1               1   \n",
              "3          93826.63           -1             -1               1   \n",
              "4          79084.10            1              1               0   \n",
              "\n",
              "   country_Germany  country_Spain  gender_Female  gender_Male  \n",
              "0                0              0              1            0  \n",
              "1                0              1              1            0  \n",
              "2                0              0              1            0  \n",
              "3                0              0              1            0  \n",
              "4                0              1              1            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa3df873-8582-453c-8df4-4304d67c0441\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>churn</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>country_France</th>\n",
              "      <th>country_Germany</th>\n",
              "      <th>country_Spain</th>\n",
              "      <th>gender_Female</th>\n",
              "      <th>gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa3df873-8582-453c-8df4-4304d67c0441')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa3df873-8582-453c-8df4-4304d67c0441 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa3df873-8582-453c-8df4-4304d67c0441');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_vars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GUjntOGMUgE",
        "outputId": "ca670388-b221-44c1-ecf9-3e2d1f324cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['credit_score',\n",
              " 'age',\n",
              " 'tenure',\n",
              " 'balance',\n",
              " 'products_number',\n",
              " 'estimated_salary']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df[continuous_vars] = scaler.fit_transform(df[continuous_vars])\n",
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5V44yj_MVjE",
        "outputId": "25201c4a-67e4-4f40-800e-02cf2e688664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of       churn  credit_score       age    tenure   balance  products_number  \\\n",
              "0         1     -0.326221  0.293517 -1.041760 -1.225848        -0.911583   \n",
              "1         0     -0.440036  0.198164 -1.387538  0.117350        -0.911583   \n",
              "2         1     -1.536794  0.293517  1.032908  1.333053         2.527057   \n",
              "3         0      0.501521  0.007457 -1.387538 -1.225848         0.807737   \n",
              "4         0      2.063884  0.388871 -1.041760  0.785728        -0.911583   \n",
              "...     ...           ...       ...       ...       ...              ...   \n",
              "9995      0      1.246488  0.007457 -0.004426 -1.225848         0.807737   \n",
              "9996      0     -1.391939 -0.373958  1.724464 -0.306379        -0.911583   \n",
              "9997      1      0.604988 -0.278604  0.687130 -1.225848        -0.911583   \n",
              "9998      1      1.256835  0.293517 -0.695982 -0.022608         0.807737   \n",
              "9999      0      1.463771 -1.041433 -0.350204  0.859965        -0.911583   \n",
              "\n",
              "      estimated_salary  credit_card  active_member  country_France  \\\n",
              "0             0.021886            1              1               1   \n",
              "1             0.216534           -1              1               0   \n",
              "2             0.240687            1             -1               1   \n",
              "3            -0.108918           -1             -1               1   \n",
              "4            -0.365276            1              1               0   \n",
              "...                ...          ...            ...             ...   \n",
              "9995         -0.066419            1             -1               1   \n",
              "9996          0.027988            1              1               1   \n",
              "9997         -1.008643           -1              1               1   \n",
              "9998         -0.125231            1             -1               0   \n",
              "9999         -1.076370            1             -1               1   \n",
              "\n",
              "      country_Germany  country_Spain  gender_Female  gender_Male  \n",
              "0                   0              0              1            0  \n",
              "1                   0              1              1            0  \n",
              "2                   0              0              1            0  \n",
              "3                   0              0              1            0  \n",
              "4                   0              1              1            0  \n",
              "...               ...            ...            ...          ...  \n",
              "9995                0              0              0            1  \n",
              "9996                0              0              0            1  \n",
              "9997                0              0              1            0  \n",
              "9998                1              0              0            1  \n",
              "9999                0              0              1            0  \n",
              "\n",
              "[10000 rows x 14 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df:\n",
        "    print(f'{col}: {df[col].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdNfj05BMWT8",
        "outputId": "6bf0786c-f4fa-42a5-b326-aa7a4df5c438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "churn: [1 0]\n",
            "credit_score: [-0.32622142 -0.44003595 -1.53679418  0.50152063  2.06388377 -0.05720525\n",
            "  1.77417405 -2.84048792 -1.54714096  0.346319   -1.26777801 -1.58852806\n",
            " -1.80581035 -1.05049572 -0.16067301 -0.35726175  0.02556895 -0.65731824\n",
            "  0.78088358  0.84296423 -0.15032623 -1.45401997  0.19111736  2.02249666\n",
            " -0.760786    1.09128685 -0.82286666 -0.79182633 -2.47835077 -0.61593114\n",
            " -1.21604413 -1.00910862 -1.35055222  0.73949648 -1.81615712 -1.66095549\n",
            "  1.58793208 -0.70905212 -1.84719745 -1.91962488 -0.97806829  1.89833536\n",
            "  0.09799638  1.29822236  1.84660148 -0.13997946 -1.04014895  0.49117386\n",
            " -0.6780118   1.42238367  0.0462625  -0.51246338  0.05660928  0.7705368\n",
            " -1.4436732  -0.3779553   0.94643199  0.37735933 -0.98841507 -0.49176983\n",
            "  1.03955297 -0.7193989   0.87400456  0.10834316  0.25319802  0.90504489\n",
            "  1.68105307  0.06695605 -0.48142306 -1.36089899  0.13938348  0.28423834\n",
            "  1.10163363 -2.42661689  0.14973026  1.30856914 -1.11257638 -1.49540708\n",
            " -1.62991516  0.01522218  1.0292062   0.81192391 -0.04685848 -0.0365117\n",
            "  1.62931919 -1.30916511  1.22579493  0.82227068 -1.4022861   1.26718204\n",
            "  1.69139984  0.61533517 -2.45765722 -0.28483432  0.20146414 -0.29518109\n",
            "  1.39134335 -0.47107628 -1.77477002  0.35666577 -1.16431025 -0.91598764\n",
            "  0.7291497  -0.23310044  0.18077059  1.8362547   0.24285124 -0.26414077\n",
            " -2.26106848  1.23614171  1.1119804   1.4948111   0.36701255  1.43273045\n",
            " -0.63662469 -1.96101198 -0.68835857 -0.74009245  0.12903671  0.32562545\n",
            "  1.47411755  0.41874643 -1.71268937 -0.00547137  1.0705933  -1.19535058\n",
            "  0.67741582 -1.15396348  0.57394806 -0.66766502 -0.20206011  0.6877626\n",
            "  1.54654498  0.33597222  0.55325451 -0.36760852  0.17042381 -1.72303614\n",
            " -1.76442325 -0.75043923 -1.43332642 -0.46072951 -0.55385049  1.31891592\n",
            " -1.41263287 -1.29881834  0.66706905 -0.72974567  1.61897241 -1.34020544\n",
            "  1.12232718 -1.39193932  0.62568194 -0.3365682  -0.0778988   0.21181091\n",
            "  0.39805288 -0.31587465  0.26354479 -0.81251988  0.46013353 -0.60558437\n",
            " -0.86425376  0.44978676 -1.07118927 -0.58489081  0.23250447 -0.4193424\n",
            "  1.20510138  1.16371428  0.63602872  0.54290774  0.11868993  0.08764961\n",
            " -1.31951189  1.25683526 -1.09188282 -0.17101979  0.91539166  1.24648849\n",
            "  0.31527867 -1.1022296   0.47048031  1.19475461  0.79123035  0.43943998\n",
            " -0.96772152 -1.23673768 -1.57818128  0.0048754   1.453424    0.85331101\n",
            "  1.66035951  0.58429484  0.65672227  1.36030302  1.28787559  1.53619821\n",
            " -0.50211661  0.96712554 -0.64697147  0.99816587 -0.69870535 -0.24344722\n",
            "  0.83261746 -0.22275366 -2.19898783 -0.08824558  1.60862564 -1.8265039\n",
            " -0.94702796 -2.29210881  0.3049319   1.01885942  0.86365778 -0.06755203\n",
            " -0.25379399 -0.01581815  1.59827886  0.69810937  1.96041601 -0.21240689\n",
            "  0.03591573  1.1533675  -0.85390698 -0.38830208 -1.32985867  0.89469811\n",
            " -0.02616493 -2.14725395 -0.10893913 -1.1436167  -1.97135876 -0.59523759\n",
            "  1.55689176 -0.40899563  1.56723853  0.97747232 -1.73338292  0.40839965\n",
            " -1.64026194  0.60498839  0.56360129 -0.93668119  1.04989975  0.52221419\n",
            " -1.17465703 -1.69199582 -0.56419726  0.53256096 -1.70234259  0.76019003\n",
            " -1.0608425  -1.92997166  1.44307722 -1.20569736  1.00851264 -1.61956839\n",
            " -0.62627792 -1.88858455 -1.46436675  1.73278694  1.71209339 -1.18500381\n",
            "  1.06024652  1.27752881 -0.30552787 -0.84356021  0.07730283  1.52585143\n",
            " -0.09859236 -1.12292315  0.4290932  -0.11928591  1.18440783 -0.83321343\n",
            " -0.12963268 -0.53315694 -0.19171334  1.32926269 -1.27812479 -0.89529409\n",
            "  1.88798858 -1.51610063  1.98110956 -1.47471353 -2.41627012 -0.54350371\n",
            "  0.93608521 -0.45038273  1.14302073  2.04319022 -1.08153605 -2.18864105\n",
            "  1.08094007  1.13267395 -1.28847156  0.64637549  0.51186741  0.16007704\n",
            " -0.87460053 -1.60922161  0.3877061  -0.39864885 -1.79546357 -2.31280236\n",
            "  1.95006923  1.74313372  0.71880292 -1.98170554 -1.5264474  -0.27448754\n",
            " -1.25743124 -0.90564086 -1.74372969  1.50515788 -2.1265604   0.98781909\n",
            "  1.40169012 -0.99876184  0.22215769  1.4120369  -1.56783451  2.00180311\n",
            " -2.07482652  1.70174662  1.93972246  1.57758531  0.88435134 -0.18136656\n",
            " -0.52281016  0.29458512 -1.38159254  1.46377078  0.95677877 -1.68164904\n",
            " -2.37488301  1.97076279  0.59464162 -1.4850603  -1.50575385 -2.01274586\n",
            " -2.23002815 -0.92633441 -1.37124577 -0.88494731  0.80157713  1.38099657\n",
            " -1.01945539 -0.42968918  1.17406106  0.48082708  0.74984325 -1.02980217\n",
            " -2.13690717  0.70845615 -1.59887483 -1.13326993  1.85694825  1.67070629\n",
            "  0.27389157 -2.38522979 -0.57454404 -0.34691497  1.63966596 -1.55748773\n",
            "  1.81556115 -2.24037493 -1.42297965 -1.7851168   1.51550465 -2.974996\n",
            " -2.60251208 -1.94031843  1.33960947 -2.05413297 -0.78147955  1.92937568\n",
            "  1.48446433  1.7948676  -2.30245558  1.78452082  1.34995624  2.05353699\n",
            " -1.67130226 -2.27141526 -2.00239909  1.21544816  1.86729503 -3.01638311\n",
            "  1.7534805  -0.8021731  -0.77113278 -0.95737474  1.72244017 -2.08517329\n",
            " -2.17829427 -2.43696367  1.76382727 -1.24708446 -3.10950409 -2.11621362\n",
            " -2.33349591  0.92573844 -1.75407647  1.37064979 -3.02672988  2.01214989\n",
            " -2.06447974 -1.99205231 -1.87823778 -2.35418946 -2.5507782   1.91902891\n",
            " -1.83685068  1.90868213 -1.90927811 -1.65060871 -3.09915731  1.82590793\n",
            "  1.99145634 -2.95430245 -1.22639091 -2.44731044 -2.04378619 -1.85754423\n",
            " -2.58181853  1.65001274  1.8776418  -1.867891   -2.10586684 -2.36453624\n",
            "  1.80521437 -2.28176203 -2.21968138 -2.32314913 -2.5093911   2.03284344\n",
            " -2.40592334 -2.2093346  -2.48869755 -2.03343941 -2.51973787 -2.02309264\n",
            " -1.95066521 -2.73702016 -2.54043142 -2.76806049 -2.64389918 -1.89893133\n",
            " -2.2507217  -2.15760072 -2.34384269 -2.09552007 -2.1679475  -2.9336089\n",
            " -2.46800399 -2.77840727 -2.87152825 -2.39557656]\n",
            "age: [ 0.29351742  0.19816383  0.00745665  0.38887101  0.4842246   1.05634615\n",
            " -0.94607926 -1.13678644 -0.75537207 -1.42284721 -0.4693113  -1.32749362\n",
            " -0.37395771  0.5795782   1.81917487 -0.66001848 -0.08789694  0.67493179\n",
            " -0.27860412 -0.56466489  0.10281024  1.15169974  2.10523565  0.96099256\n",
            " -0.18325053 -1.89961516  2.5820036   1.62846769 -1.23214003 -1.70890798\n",
            "  1.5331141   3.44018592 -1.61355439 -0.85072567 -1.04143285  2.48665001\n",
            "  0.86563897  1.24705333  1.72382128  3.24947873  0.77028538  1.43776051\n",
            "  3.15412514 -1.80426157  2.67735719  3.82160028  2.20058924  1.34240692\n",
            "  3.91695387  1.91452846  2.77271078 -1.5182008   2.00988206  2.96341796\n",
            "  2.29594283  2.39129642 -1.99496875  4.10766105  2.86806437  3.34483233\n",
            "  3.05877155  3.53553951  3.6308931   4.6797826   4.39372182  4.29836823\n",
            "  3.72624669  4.01230746  5.06119696  4.20301464]\n",
            "tenure: [-1.04175968 -1.38753759  1.03290776  0.68712986 -0.35020386  0.34135195\n",
            " -0.69598177  1.72446358 -0.00442596  1.37868567 -1.73331549]\n",
            "balance: [-1.22584767  0.11735002  1.33305335 ... -0.30637869 -0.02260751\n",
            "  0.85996499]\n",
            "products_number: [-0.91158349  2.52705662  0.80773656  4.24637668]\n",
            "estimated_salary: [ 0.02188649  0.21653375  0.2406869  ... -1.00864308 -0.12523071\n",
            " -1.07636976]\n",
            "credit_card: [ 1 -1]\n",
            "active_member: [ 1 -1]\n",
            "country_France: [1 0]\n",
            "country_Germany: [0 1]\n",
            "country_Spain: [0 1]\n",
            "gender_Female: [1 0]\n",
            "gender_Male: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=df['churn']\n",
        "X= df.drop(labels='churn', axis='columns')"
      ],
      "metadata": {
        "id": "wyDZvku_MXIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.to_numpy()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV8_AvWxMYB1",
        "outputId": "7549e910-9490-43bc-eae6-b9c474ddbb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.32622142,  0.29351742, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [ 0.        , -0.44003595,  0.19816383, ...,  1.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [ 1.        , -1.53679418,  0.29351742, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 1.        ,  0.60498839, -0.27860412, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [ 1.        ,  1.25683526,  0.29351742, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.        ,  1.46377078, -1.04143285, ...,  0.        ,\n",
              "         1.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=Y.to_numpy()\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yon6NgGLMYxo",
        "outputId": "81cb8a35-b8d2-4efa-ce24-e773a54d1572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X.to_numpy()\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sxePvHgMZhV",
        "outputId": "4a5bac9e-0355-4304-bca8-451d31b4a247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.32622142,  0.29351742, -1.04175968, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [-0.44003595,  0.19816383, -1.38753759, ...,  1.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [-1.53679418,  0.29351742,  1.03290776, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.60498839, -0.27860412,  0.68712986, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [ 1.25683526,  0.29351742, -0.69598177, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 1.46377078, -1.04143285, -0.35020386, ...,  0.        ,\n",
              "         1.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=30, test_size = .2)\n",
        "\n"
      ],
      "metadata": {
        "id": "lh0pCzS0MaL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tf = tf.stack(X_train)\n",
        "Y_train_tf = tf.stack(Y_train)\n",
        "X_test_tf = tf.stack(X_test)\n",
        "Y_test_tf = tf.stack(Y_test)"
      ],
      "metadata": {
        "id": "KPyHlzh8kcJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vYlAbKoMcGx",
        "outputId": "5922448d-111e-493d-8924-fb13ee072ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwNYsNvPI3Nv",
        "outputId": "f2aec98d-0ddf-4b5f-950b-cfe1d44430d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIRJyygQJZnj",
        "outputId": "618fe37a-9a75-42d1-f9e5-c37f88f24780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.17465703,  2.5820036 ,  1.03290776, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.49117386,  1.62846769, -1.38753759, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.19111736,  0.5795782 ,  0.68712986, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       ...,\n",
              "       [-0.7193989 , -0.85072567, -1.38753759, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.60498839,  0.00745665,  1.03290776, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 1.95006923,  1.15169974, -0.69598177, ...,  0.        ,\n",
              "         1.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjVB9jH6JbsT",
        "outputId": "e6be68e0-5743-4daf-f15e-ead5e7b57272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Hyperparamter tuning using random search with the random method \"quantum\"***\n"
      ],
      "metadata": {
        "id": "vkFGy8L0Nt6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.optimizer_v2 import adam as adam_v2\n",
        "from tensorflow.python.keras.optimizer_v2 import optimizer_v2"
      ],
      "metadata": {
        "id": "eF7vE5PYVFHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We set the parameter space\n",
        "p = {'lr': [0.01, 0.1],\n",
        "     'first_neuron':[32, 64],\n",
        "     'hidden_layers':[2, 3, 4, 5],\n",
        "     'batch_size': [32, 64],\n",
        "     'epochs': [100],\n",
        "     'dropout': [0, 0.5],\n",
        "     'weight_regulizer':['GlorotNormal', 'HeNormal'],\n",
        "     'shape':['brick','long_funnel'],\n",
        "     'optimizer': ['Adam', 'Nadam', 'Adamax'],\n",
        "     'losses': ['logcosh', 'binary_crossentropy'],\n",
        "     'activation':['relu', 'elu'],\n",
        "     'last_activation': ['sigmoid']}"
      ],
      "metadata": {
        "id": "i4ybCRjz6UD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "\n",
        "# defining/creating a sequential model\n",
        "\n",
        "def achraf_model(X_train, Y_train, X_test, Y_test, params): \n",
        "  model = Sequential()\n",
        "  model.add(Dense(params['first_neuron'], kernel_initializer=params['weight_regulizer'], kernel_regularizer=regularizers.l2(0.09), input_shape=(n_features,), activation=params['activation']))\n",
        "  BatchNormalization()\n",
        "  model.add(Dense(77, kernel_initializer=params['weight_regulizer'], kernel_regularizer=regularizers.l2(0.08), activation=params['activation']))\n",
        "  BatchNormalization()\n",
        "  model.add(Dense(70, kernel_initializer=params['weight_regulizer'], kernel_regularizer=regularizers.l2(0.07), activation=params['activation']))\n",
        "  BatchNormalization()\n",
        "  model.add(Dense(70,  kernel_initializer=params['weight_regulizer'], kernel_regularizer=regularizers.l2(0.06), activation=params['activation']))\n",
        "  BatchNormalization()\n",
        "  model.add(Dense(63, kernel_initializer=params['weight_regulizer'], activation=params['activation']))\n",
        "  BatchNormalization(\n",
        "              momentum=0.95, \n",
        "              epsilon=0.005,\n",
        "              center = True,\n",
        "              scale = True,\n",
        "              beta_initializer='zeros', \n",
        "              gamma_initializer='ones',\n",
        "              moving_mean_initializer='zeros',\n",
        "            moving_variance_initializer='ones',\n",
        "            beta_regularizer=None,\n",
        "            gamma_regularizer=None,\n",
        "            beta_constraint=None,\n",
        "            gamma_constraint=None,\n",
        "            ),\n",
        "  model.add(Dense(1, activation=params['last_activation'], name=\"predictions\"))\n",
        "\n",
        "  model.compile(optimizer=params['optimizer'], loss=params['losses'], metrics=['accuracy'])\n",
        "  model.summary\n",
        "\n",
        "  history = model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    epochs=51, \n",
        "    validation_split=0.25, \n",
        "    batch_size=32, \n",
        "    verbose=2,\n",
        "    validation_data=(X_test, Y_test)\n",
        ")\n",
        "  \n",
        "  return history, model"
      ],
      "metadata": {
        "id": "zIeXujYnMcRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparamter tuning using random search with the random method \"quantum\"\n",
        "scan_object = ta.Scan(x = X_train,\n",
        "            y = Y_train,\n",
        "            x_val=X_test,\n",
        "            y_val=Y_test,\n",
        "            params=p,\n",
        "            model = achraf_model,\n",
        "            experiment_name='churn',\n",
        "            random_method='quantum',\n",
        "            fraction_limit = 0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_mTZtCszbz_",
        "outputId": "12a0b0d7-9b86-4cc8-ad11-f03eb4f1e447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 3s - loss: 6.9104 - accuracy: 0.7917 - val_loss: 1.8544 - val_accuracy: 0.8085\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 0.9964 - accuracy: 0.7968 - val_loss: 0.5907 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.5540 - accuracy: 0.7968 - val_loss: 0.4995 - val_accuracy: 0.8090\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5179 - accuracy: 0.7975 - val_loss: 0.4923 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.5103 - accuracy: 0.7998 - val_loss: 0.4913 - val_accuracy: 0.8175\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.5043 - accuracy: 0.8018 - val_loss: 0.4750 - val_accuracy: 0.8080\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.4998 - accuracy: 0.8022 - val_loss: 0.4680 - val_accuracy: 0.8125\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.4956 - accuracy: 0.8007 - val_loss: 0.4884 - val_accuracy: 0.8085\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.4934 - accuracy: 0.8013 - val_loss: 0.4599 - val_accuracy: 0.8210\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.4887 - accuracy: 0.8033 - val_loss: 0.4567 - val_accuracy: 0.8160\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.4882 - accuracy: 0.8012 - val_loss: 0.4529 - val_accuracy: 0.8305\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.4858 - accuracy: 0.8028 - val_loss: 0.4524 - val_accuracy: 0.8190\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.4845 - accuracy: 0.8050 - val_loss: 0.4858 - val_accuracy: 0.8210\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.4849 - accuracy: 0.8010 - val_loss: 0.4854 - val_accuracy: 0.8315\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.4822 - accuracy: 0.8033 - val_loss: 0.4599 - val_accuracy: 0.8140\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4815 - accuracy: 0.8037 - val_loss: 0.4506 - val_accuracy: 0.8160\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.4792 - accuracy: 0.8040 - val_loss: 0.4446 - val_accuracy: 0.8295\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.4783 - accuracy: 0.8033 - val_loss: 0.4463 - val_accuracy: 0.8220\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.4773 - accuracy: 0.8043 - val_loss: 0.4447 - val_accuracy: 0.8240\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.4764 - accuracy: 0.8045 - val_loss: 0.4435 - val_accuracy: 0.8350\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.4762 - accuracy: 0.8032 - val_loss: 0.4613 - val_accuracy: 0.8285\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.4747 - accuracy: 0.8033 - val_loss: 0.4609 - val_accuracy: 0.8185\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.4753 - accuracy: 0.8033 - val_loss: 0.4537 - val_accuracy: 0.8210\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.4730 - accuracy: 0.8020 - val_loss: 0.4385 - val_accuracy: 0.8255\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.4747 - accuracy: 0.8068 - val_loss: 0.4493 - val_accuracy: 0.8290\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.4740 - accuracy: 0.8010 - val_loss: 0.4473 - val_accuracy: 0.8330\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.4734 - accuracy: 0.8007 - val_loss: 0.4374 - val_accuracy: 0.8235\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.4725 - accuracy: 0.8040 - val_loss: 0.4394 - val_accuracy: 0.8175\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.4724 - accuracy: 0.8032 - val_loss: 0.4612 - val_accuracy: 0.8090\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.4707 - accuracy: 0.8057 - val_loss: 0.4405 - val_accuracy: 0.8170\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.4698 - accuracy: 0.8032 - val_loss: 0.4487 - val_accuracy: 0.8310\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.4712 - accuracy: 0.7998 - val_loss: 0.4397 - val_accuracy: 0.8215\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.4701 - accuracy: 0.8027 - val_loss: 0.4376 - val_accuracy: 0.8175\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.4694 - accuracy: 0.8038 - val_loss: 0.4402 - val_accuracy: 0.8290\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.4683 - accuracy: 0.8047 - val_loss: 0.4346 - val_accuracy: 0.8195\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.4686 - accuracy: 0.8027 - val_loss: 0.4457 - val_accuracy: 0.8275\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.4686 - accuracy: 0.8055 - val_loss: 0.4422 - val_accuracy: 0.8110\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.4681 - accuracy: 0.8033 - val_loss: 0.4390 - val_accuracy: 0.8200\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.4681 - accuracy: 0.8025 - val_loss: 0.4377 - val_accuracy: 0.8285\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.4679 - accuracy: 0.8025 - val_loss: 0.4341 - val_accuracy: 0.8215\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.4671 - accuracy: 0.8050 - val_loss: 0.4398 - val_accuracy: 0.8215\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.4673 - accuracy: 0.8055 - val_loss: 0.4321 - val_accuracy: 0.8265\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.4666 - accuracy: 0.8050 - val_loss: 0.4390 - val_accuracy: 0.8255\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.4648 - accuracy: 0.8055 - val_loss: 0.4374 - val_accuracy: 0.8185\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.4690 - accuracy: 0.8020 - val_loss: 0.4330 - val_accuracy: 0.8295\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.4683 - accuracy: 0.8023 - val_loss: 0.4567 - val_accuracy: 0.8230\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.4687 - accuracy: 0.8047 - val_loss: 0.4397 - val_accuracy: 0.8175\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.4686 - accuracy: 0.8030 - val_loss: 0.4359 - val_accuracy: 0.8185\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.4674 - accuracy: 0.8023 - val_loss: 0.4322 - val_accuracy: 0.8305\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.4650 - accuracy: 0.8030 - val_loss: 0.4314 - val_accuracy: 0.8245\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.4647 - accuracy: 0.8085 - val_loss: 0.4364 - val_accuracy: 0.8325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 1/30 [00:43<20:59, 43.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 22.9144 - accuracy: 0.7907 - val_loss: 13.2793 - val_accuracy: 0.8120\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 8.6475 - accuracy: 0.7985 - val_loss: 5.2425 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 3.5382 - accuracy: 0.7967 - val_loss: 2.2559 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 1.6281 - accuracy: 0.7967 - val_loss: 1.1367 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.9124 - accuracy: 0.7967 - val_loss: 0.7163 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.6437 - accuracy: 0.7967 - val_loss: 0.5606 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5477 - accuracy: 0.7967 - val_loss: 0.5097 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5174 - accuracy: 0.7967 - val_loss: 0.4933 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.5085 - accuracy: 0.7967 - val_loss: 0.4902 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.5062 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4888 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4894 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 2/30 [01:07<15:04, 32.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 20.0523 - accuracy: 0.8083 - val_loss: 9.4451 - val_accuracy: 0.8270\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 5.5054 - accuracy: 0.8073 - val_loss: 2.9434 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.9650 - accuracy: 0.7988 - val_loss: 1.2698 - val_accuracy: 0.8135\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 1.0017 - accuracy: 0.7982 - val_loss: 0.7681 - val_accuracy: 0.8085\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.6915 - accuracy: 0.8005 - val_loss: 0.5965 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5832 - accuracy: 0.7980 - val_loss: 0.5276 - val_accuracy: 0.8085\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5371 - accuracy: 0.8000 - val_loss: 0.5048 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5187 - accuracy: 0.7987 - val_loss: 0.4904 - val_accuracy: 0.8130\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5160 - accuracy: 0.8010 - val_loss: 0.4820 - val_accuracy: 0.8115\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5043 - accuracy: 0.8003 - val_loss: 0.4723 - val_accuracy: 0.8145\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.5045 - accuracy: 0.7997 - val_loss: 0.4752 - val_accuracy: 0.8200\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5010 - accuracy: 0.8010 - val_loss: 0.4657 - val_accuracy: 0.8210\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.4975 - accuracy: 0.8017 - val_loss: 0.4673 - val_accuracy: 0.8220\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.4961 - accuracy: 0.8027 - val_loss: 0.4665 - val_accuracy: 0.8160\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.4913 - accuracy: 0.8012 - val_loss: 0.4986 - val_accuracy: 0.8280\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4926 - accuracy: 0.8005 - val_loss: 0.4676 - val_accuracy: 0.8160\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.4916 - accuracy: 0.8015 - val_loss: 0.4668 - val_accuracy: 0.8120\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.4906 - accuracy: 0.7978 - val_loss: 0.4596 - val_accuracy: 0.8130\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.4887 - accuracy: 0.8017 - val_loss: 0.4545 - val_accuracy: 0.8200\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.4869 - accuracy: 0.8043 - val_loss: 0.4575 - val_accuracy: 0.8105\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.4899 - accuracy: 0.8030 - val_loss: 0.4646 - val_accuracy: 0.8285\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.4860 - accuracy: 0.8055 - val_loss: 0.4625 - val_accuracy: 0.8345\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.4851 - accuracy: 0.8023 - val_loss: 0.4553 - val_accuracy: 0.8200\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.4809 - accuracy: 0.8045 - val_loss: 0.5028 - val_accuracy: 0.8180\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.4891 - accuracy: 0.8028 - val_loss: 0.4701 - val_accuracy: 0.8300\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.4829 - accuracy: 0.8017 - val_loss: 0.4486 - val_accuracy: 0.8180\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.4815 - accuracy: 0.8040 - val_loss: 0.4469 - val_accuracy: 0.8180\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.4788 - accuracy: 0.8052 - val_loss: 0.4482 - val_accuracy: 0.8195\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.4783 - accuracy: 0.8008 - val_loss: 0.4537 - val_accuracy: 0.8195\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.4799 - accuracy: 0.8023 - val_loss: 0.4471 - val_accuracy: 0.8180\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.4816 - accuracy: 0.8033 - val_loss: 0.4464 - val_accuracy: 0.8180\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.4797 - accuracy: 0.8008 - val_loss: 0.4452 - val_accuracy: 0.8295\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.4749 - accuracy: 0.8045 - val_loss: 0.4466 - val_accuracy: 0.8230\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.4773 - accuracy: 0.8058 - val_loss: 0.4466 - val_accuracy: 0.8295\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.4804 - accuracy: 0.8027 - val_loss: 0.4439 - val_accuracy: 0.8185\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.4769 - accuracy: 0.8030 - val_loss: 0.4410 - val_accuracy: 0.8225\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.4756 - accuracy: 0.8040 - val_loss: 0.4397 - val_accuracy: 0.8235\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.4789 - accuracy: 0.8037 - val_loss: 0.4393 - val_accuracy: 0.8255\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.4756 - accuracy: 0.8042 - val_loss: 0.4415 - val_accuracy: 0.8340\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.4723 - accuracy: 0.8073 - val_loss: 0.4492 - val_accuracy: 0.8305\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.4755 - accuracy: 0.8020 - val_loss: 0.4405 - val_accuracy: 0.8195\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.4774 - accuracy: 0.8033 - val_loss: 0.4406 - val_accuracy: 0.8250\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.4727 - accuracy: 0.8052 - val_loss: 0.4540 - val_accuracy: 0.8120\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.4767 - accuracy: 0.8032 - val_loss: 0.4381 - val_accuracy: 0.8240\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.4769 - accuracy: 0.8033 - val_loss: 0.4508 - val_accuracy: 0.8230\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.4775 - accuracy: 0.8052 - val_loss: 0.4506 - val_accuracy: 0.8285\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.4805 - accuracy: 0.8015 - val_loss: 0.4584 - val_accuracy: 0.8120\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.4769 - accuracy: 0.8017 - val_loss: 0.4422 - val_accuracy: 0.8185\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.4765 - accuracy: 0.8035 - val_loss: 0.4375 - val_accuracy: 0.8250\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.4721 - accuracy: 0.8058 - val_loss: 0.4521 - val_accuracy: 0.8315\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.4717 - accuracy: 0.8040 - val_loss: 0.4484 - val_accuracy: 0.8300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 3/30 [01:36<13:46, 30.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 3s - loss: 5.9150 - accuracy: 0.7863 - val_loss: 1.6990 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 0.9559 - accuracy: 0.7967 - val_loss: 0.5930 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 0.5472 - accuracy: 0.7967 - val_loss: 0.4991 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5107 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.5065 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4898 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.5061 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4901 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.5063 - accuracy: 0.7967 - val_loss: 0.4892 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.5061 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4894 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4892 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.5062 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4886 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4907 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.5061 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|        | 4/30 [02:04<12:46, 29.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 22.1426 - accuracy: 0.7967 - val_loss: 9.9356 - val_accuracy: 0.8090\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 5.6241 - accuracy: 0.7967 - val_loss: 2.8837 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.7894 - accuracy: 0.7967 - val_loss: 1.0370 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.6890 - accuracy: 0.7967 - val_loss: 0.4294 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.3018 - accuracy: 0.7967 - val_loss: 0.2008 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.1550 - accuracy: 0.7967 - val_loss: 0.1149 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.1011 - accuracy: 0.7967 - val_loss: 0.0847 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0826 - accuracy: 0.7967 - val_loss: 0.0747 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0769 - accuracy: 0.7967 - val_loss: 0.0718 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0753 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0716 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0715 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0717 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 5/30 [02:47<14:18, 34.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 6.8717 - accuracy: 0.7965 - val_loss: 1.8213 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 0.9649 - accuracy: 0.7967 - val_loss: 0.5663 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.5309 - accuracy: 0.7967 - val_loss: 0.4963 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.5071 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4891 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4900 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4892 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4895 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4927 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4896 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4891 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4924 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.5062 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4923 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4893 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4888 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.5050 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 6/30 [03:15<12:53, 32.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 23.3847 - accuracy: 0.7888 - val_loss: 11.4261 - val_accuracy: 0.8100\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 6.6812 - accuracy: 0.7965 - val_loss: 3.4937 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 2.1097 - accuracy: 0.7967 - val_loss: 1.1493 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.7160 - accuracy: 0.7967 - val_loss: 0.4060 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.2681 - accuracy: 0.7967 - val_loss: 0.1658 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.1263 - accuracy: 0.7967 - val_loss: 0.0936 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.0860 - accuracy: 0.7967 - val_loss: 0.0752 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.0766 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|       | 7/30 [03:39<11:21, 29.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 20.9761 - accuracy: 0.8028 - val_loss: 10.1437 - val_accuracy: 0.8320\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 5.9333 - accuracy: 0.8013 - val_loss: 3.1774 - val_accuracy: 0.8220\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 2.0771 - accuracy: 0.7975 - val_loss: 1.3110 - val_accuracy: 0.8090\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 1.0127 - accuracy: 0.7963 - val_loss: 0.7715 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.6870 - accuracy: 0.7963 - val_loss: 0.5910 - val_accuracy: 0.8090\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5769 - accuracy: 0.7968 - val_loss: 0.5252 - val_accuracy: 0.8090\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5364 - accuracy: 0.7975 - val_loss: 0.5000 - val_accuracy: 0.8090\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5177 - accuracy: 0.8003 - val_loss: 0.4999 - val_accuracy: 0.8090\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5114 - accuracy: 0.7980 - val_loss: 0.4794 - val_accuracy: 0.8105\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5040 - accuracy: 0.8015 - val_loss: 0.4724 - val_accuracy: 0.8260\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.5017 - accuracy: 0.7983 - val_loss: 0.4693 - val_accuracy: 0.8175\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.4981 - accuracy: 0.8015 - val_loss: 0.4736 - val_accuracy: 0.8270\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.4963 - accuracy: 0.7993 - val_loss: 0.4686 - val_accuracy: 0.8105\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.4934 - accuracy: 0.8020 - val_loss: 0.4612 - val_accuracy: 0.8265\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.4903 - accuracy: 0.8050 - val_loss: 0.4586 - val_accuracy: 0.8195\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4887 - accuracy: 0.8058 - val_loss: 0.4583 - val_accuracy: 0.8190\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.4878 - accuracy: 0.8007 - val_loss: 0.4557 - val_accuracy: 0.8170\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.4858 - accuracy: 0.8042 - val_loss: 0.4709 - val_accuracy: 0.8110\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.4839 - accuracy: 0.8007 - val_loss: 0.4836 - val_accuracy: 0.8185\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.4833 - accuracy: 0.8037 - val_loss: 0.4531 - val_accuracy: 0.8195\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.4811 - accuracy: 0.8028 - val_loss: 0.4523 - val_accuracy: 0.8175\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.4822 - accuracy: 0.8015 - val_loss: 0.4718 - val_accuracy: 0.8200\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.4798 - accuracy: 0.8042 - val_loss: 0.4501 - val_accuracy: 0.8320\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.4799 - accuracy: 0.8045 - val_loss: 0.4591 - val_accuracy: 0.8330\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.4787 - accuracy: 0.8048 - val_loss: 0.4445 - val_accuracy: 0.8195\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.4771 - accuracy: 0.8028 - val_loss: 0.4819 - val_accuracy: 0.8235\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.4768 - accuracy: 0.8023 - val_loss: 0.4408 - val_accuracy: 0.8275\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.4756 - accuracy: 0.8022 - val_loss: 0.4508 - val_accuracy: 0.8290\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.4754 - accuracy: 0.8062 - val_loss: 0.4400 - val_accuracy: 0.8310\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.4752 - accuracy: 0.8047 - val_loss: 0.4407 - val_accuracy: 0.8220\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.4751 - accuracy: 0.8002 - val_loss: 0.4402 - val_accuracy: 0.8235\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.4743 - accuracy: 0.8052 - val_loss: 0.4403 - val_accuracy: 0.8280\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.4744 - accuracy: 0.8042 - val_loss: 0.4451 - val_accuracy: 0.8140\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.4734 - accuracy: 0.8057 - val_loss: 0.4459 - val_accuracy: 0.8145\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.4713 - accuracy: 0.8048 - val_loss: 0.4443 - val_accuracy: 0.8320\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.4717 - accuracy: 0.8045 - val_loss: 0.4420 - val_accuracy: 0.8155\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.4712 - accuracy: 0.8048 - val_loss: 0.4392 - val_accuracy: 0.8195\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.4702 - accuracy: 0.8047 - val_loss: 0.4390 - val_accuracy: 0.8215\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.4690 - accuracy: 0.8078 - val_loss: 0.4433 - val_accuracy: 0.8270\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.4708 - accuracy: 0.8025 - val_loss: 0.4535 - val_accuracy: 0.8295\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.4705 - accuracy: 0.8027 - val_loss: 0.4362 - val_accuracy: 0.8225\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.4683 - accuracy: 0.8062 - val_loss: 0.4349 - val_accuracy: 0.8245\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.4686 - accuracy: 0.8038 - val_loss: 0.4635 - val_accuracy: 0.8130\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.4697 - accuracy: 0.8028 - val_loss: 0.4339 - val_accuracy: 0.8255\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.4695 - accuracy: 0.8007 - val_loss: 0.4348 - val_accuracy: 0.8335\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.4674 - accuracy: 0.8033 - val_loss: 0.4420 - val_accuracy: 0.8300\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.4674 - accuracy: 0.8070 - val_loss: 0.4369 - val_accuracy: 0.8250\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.4681 - accuracy: 0.8038 - val_loss: 0.4467 - val_accuracy: 0.8175\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.4671 - accuracy: 0.8077 - val_loss: 0.4319 - val_accuracy: 0.8275\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.4679 - accuracy: 0.8042 - val_loss: 0.4368 - val_accuracy: 0.8315\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.4654 - accuracy: 0.8045 - val_loss: 0.4628 - val_accuracy: 0.8190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 8/30 [04:22<12:25, 33.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 6.3840 - accuracy: 0.7838 - val_loss: 1.9320 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 1.0774 - accuracy: 0.7967 - val_loss: 0.6369 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.5677 - accuracy: 0.7967 - val_loss: 0.5069 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5141 - accuracy: 0.7967 - val_loss: 0.4904 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.5062 - accuracy: 0.7967 - val_loss: 0.4890 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.5063 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4894 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4904 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4890 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4913 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4884 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5050 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4897 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4901 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4891 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4895 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4904 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 9/30 [04:50<11:14, 32.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 6.7283 - accuracy: 0.7907 - val_loss: 1.8210 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 0.7771 - accuracy: 0.7967 - val_loss: 0.2500 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 0.1427 - accuracy: 0.7967 - val_loss: 0.0859 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.0800 - accuracy: 0.7967 - val_loss: 0.0718 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.0750 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0716 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0715 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 10/30 [05:33<11:44, 35.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 6.1150 - accuracy: 0.7908 - val_loss: 1.8678 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 0.8554 - accuracy: 0.7967 - val_loss: 0.3122 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.1789 - accuracy: 0.7967 - val_loss: 0.1026 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.0882 - accuracy: 0.7967 - val_loss: 0.0748 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.0763 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 11/30 [05:57<10:07, 31.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 6.9455 - accuracy: 0.7918 - val_loss: 1.8395 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 0.9797 - accuracy: 0.7967 - val_loss: 0.5822 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 0.5336 - accuracy: 0.7967 - val_loss: 0.4919 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5074 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4908 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4902 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4916 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4897 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4894 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4905 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4902 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 12/30 [06:40<10:36, 35.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 20.1489 - accuracy: 0.8078 - val_loss: 9.4378 - val_accuracy: 0.8240\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 5.4450 - accuracy: 0.8050 - val_loss: 2.8491 - val_accuracy: 0.8120\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.8672 - accuracy: 0.7970 - val_loss: 1.1828 - val_accuracy: 0.8185\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.9233 - accuracy: 0.7953 - val_loss: 0.7104 - val_accuracy: 0.8090\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.6455 - accuracy: 0.7968 - val_loss: 0.5581 - val_accuracy: 0.8150\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.5627 - accuracy: 0.7968 - val_loss: 0.5110 - val_accuracy: 0.8080\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5272 - accuracy: 0.7982 - val_loss: 0.4893 - val_accuracy: 0.8150\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5151 - accuracy: 0.7998 - val_loss: 0.4875 - val_accuracy: 0.8085\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7985 - val_loss: 0.4792 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5031 - accuracy: 0.8000 - val_loss: 0.4769 - val_accuracy: 0.8085\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.5024 - accuracy: 0.8010 - val_loss: 0.4693 - val_accuracy: 0.8185\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.5000 - accuracy: 0.8003 - val_loss: 0.4669 - val_accuracy: 0.8185\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.4933 - accuracy: 0.8010 - val_loss: 0.4909 - val_accuracy: 0.8105\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5048 - accuracy: 0.7992 - val_loss: 0.4619 - val_accuracy: 0.8165\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.4915 - accuracy: 0.8037 - val_loss: 0.4692 - val_accuracy: 0.8090\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4877 - accuracy: 0.7997 - val_loss: 0.4563 - val_accuracy: 0.8195\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.4883 - accuracy: 0.8010 - val_loss: 0.4598 - val_accuracy: 0.8235\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.4896 - accuracy: 0.8032 - val_loss: 0.4526 - val_accuracy: 0.8265\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.4871 - accuracy: 0.8010 - val_loss: 0.4604 - val_accuracy: 0.8250\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.4866 - accuracy: 0.8008 - val_loss: 0.4694 - val_accuracy: 0.8085\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.4849 - accuracy: 0.8032 - val_loss: 0.4508 - val_accuracy: 0.8235\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.4896 - accuracy: 0.8030 - val_loss: 0.4519 - val_accuracy: 0.8200\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.4824 - accuracy: 0.8048 - val_loss: 0.4522 - val_accuracy: 0.8135\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.4818 - accuracy: 0.8030 - val_loss: 0.4485 - val_accuracy: 0.8190\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.4818 - accuracy: 0.8003 - val_loss: 0.4474 - val_accuracy: 0.8205\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.4784 - accuracy: 0.8030 - val_loss: 0.4496 - val_accuracy: 0.8250\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.4777 - accuracy: 0.8015 - val_loss: 0.4510 - val_accuracy: 0.8130\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.4791 - accuracy: 0.8025 - val_loss: 0.4482 - val_accuracy: 0.8150\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.4839 - accuracy: 0.7988 - val_loss: 0.4490 - val_accuracy: 0.8325\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.4802 - accuracy: 0.8060 - val_loss: 0.4591 - val_accuracy: 0.8275\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.4778 - accuracy: 0.8033 - val_loss: 0.4442 - val_accuracy: 0.8210\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.4753 - accuracy: 0.8032 - val_loss: 0.4691 - val_accuracy: 0.8090\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.4757 - accuracy: 0.8028 - val_loss: 0.4490 - val_accuracy: 0.8295\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.4775 - accuracy: 0.8035 - val_loss: 0.4430 - val_accuracy: 0.8245\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.4782 - accuracy: 0.8028 - val_loss: 0.4511 - val_accuracy: 0.8105\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.4785 - accuracy: 0.8022 - val_loss: 0.4467 - val_accuracy: 0.8320\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.4755 - accuracy: 0.8010 - val_loss: 0.4439 - val_accuracy: 0.8180\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.4761 - accuracy: 0.8012 - val_loss: 0.4396 - val_accuracy: 0.8215\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.4742 - accuracy: 0.8048 - val_loss: 0.4450 - val_accuracy: 0.8310\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.4728 - accuracy: 0.8040 - val_loss: 0.4378 - val_accuracy: 0.8205\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.4714 - accuracy: 0.8045 - val_loss: 0.4404 - val_accuracy: 0.8205\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.4717 - accuracy: 0.8055 - val_loss: 0.4419 - val_accuracy: 0.8320\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.4724 - accuracy: 0.8037 - val_loss: 0.4458 - val_accuracy: 0.8125\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.4726 - accuracy: 0.8060 - val_loss: 0.4479 - val_accuracy: 0.8305\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.4694 - accuracy: 0.8035 - val_loss: 0.4370 - val_accuracy: 0.8295\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.4695 - accuracy: 0.8048 - val_loss: 0.4431 - val_accuracy: 0.8305\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.4742 - accuracy: 0.8062 - val_loss: 0.4384 - val_accuracy: 0.8190\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.4720 - accuracy: 0.8037 - val_loss: 0.4386 - val_accuracy: 0.8215\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.4732 - accuracy: 0.8017 - val_loss: 0.4565 - val_accuracy: 0.8185\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.4716 - accuracy: 0.8023 - val_loss: 0.4546 - val_accuracy: 0.8280\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.4693 - accuracy: 0.8038 - val_loss: 0.4489 - val_accuracy: 0.8165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 13/30 [07:07<09:15, 32.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 27.5055 - accuracy: 0.8057 - val_loss: 16.6677 - val_accuracy: 0.8330\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 11.0163 - accuracy: 0.8117 - val_loss: 6.7487 - val_accuracy: 0.8205\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 4.5329 - accuracy: 0.8035 - val_loss: 2.8419 - val_accuracy: 0.8105\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 1.9966 - accuracy: 0.7973 - val_loss: 1.3388 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 1.0351 - accuracy: 0.7967 - val_loss: 0.7816 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.6848 - accuracy: 0.7967 - val_loss: 0.5817 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5559 - accuracy: 0.7967 - val_loss: 0.5088 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5156 - accuracy: 0.7967 - val_loss: 0.4943 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.5075 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4911 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4886 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4892 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4896 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4886 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4897 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 14/30 [07:31<08:01, 30.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 19.7976 - accuracy: 0.7922 - val_loss: 9.6687 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 5.6065 - accuracy: 0.7967 - val_loss: 2.8709 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 1.6943 - accuracy: 0.7967 - val_loss: 0.8873 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5405 - accuracy: 0.7967 - val_loss: 0.2988 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.2008 - accuracy: 0.7967 - val_loss: 0.1290 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.1052 - accuracy: 0.7967 - val_loss: 0.0837 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.0810 - accuracy: 0.7967 - val_loss: 0.0732 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.0757 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 15/30 [07:54<07:00, 28.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 21.5196 - accuracy: 0.7990 - val_loss: 10.5803 - val_accuracy: 0.8135\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 6.2315 - accuracy: 0.8000 - val_loss: 3.3426 - val_accuracy: 0.8130\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 2.1864 - accuracy: 0.7960 - val_loss: 1.3735 - val_accuracy: 0.8085\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 1.0476 - accuracy: 0.7970 - val_loss: 0.7829 - val_accuracy: 0.8085\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.6960 - accuracy: 0.7965 - val_loss: 0.5939 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5776 - accuracy: 0.7970 - val_loss: 0.5244 - val_accuracy: 0.8090\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5354 - accuracy: 0.7970 - val_loss: 0.4986 - val_accuracy: 0.8105\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5190 - accuracy: 0.7998 - val_loss: 0.4875 - val_accuracy: 0.8090\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5099 - accuracy: 0.8020 - val_loss: 0.4791 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7990 - val_loss: 0.4771 - val_accuracy: 0.8085\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.5018 - accuracy: 0.8007 - val_loss: 0.4875 - val_accuracy: 0.8285\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.4976 - accuracy: 0.8023 - val_loss: 0.4725 - val_accuracy: 0.8090\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.4951 - accuracy: 0.8013 - val_loss: 0.4710 - val_accuracy: 0.8265\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.4930 - accuracy: 0.8007 - val_loss: 0.4627 - val_accuracy: 0.8135\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.4897 - accuracy: 0.8002 - val_loss: 0.4776 - val_accuracy: 0.8200\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4878 - accuracy: 0.8048 - val_loss: 0.4679 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.4877 - accuracy: 0.8048 - val_loss: 0.4525 - val_accuracy: 0.8270\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.4864 - accuracy: 0.8023 - val_loss: 0.4522 - val_accuracy: 0.8225\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.4854 - accuracy: 0.8010 - val_loss: 0.4664 - val_accuracy: 0.8300\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.4831 - accuracy: 0.8043 - val_loss: 0.4526 - val_accuracy: 0.8185\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.4813 - accuracy: 0.8023 - val_loss: 0.4697 - val_accuracy: 0.8090\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.4828 - accuracy: 0.8033 - val_loss: 0.4512 - val_accuracy: 0.8155\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.4806 - accuracy: 0.8045 - val_loss: 0.4539 - val_accuracy: 0.8205\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.4810 - accuracy: 0.8018 - val_loss: 0.4475 - val_accuracy: 0.8205\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.4774 - accuracy: 0.8048 - val_loss: 0.4477 - val_accuracy: 0.8175\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.4777 - accuracy: 0.8025 - val_loss: 0.4445 - val_accuracy: 0.8205\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.4770 - accuracy: 0.8033 - val_loss: 0.4443 - val_accuracy: 0.8210\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.4776 - accuracy: 0.8008 - val_loss: 0.4457 - val_accuracy: 0.8175\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.4755 - accuracy: 0.8075 - val_loss: 0.4574 - val_accuracy: 0.8085\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.4749 - accuracy: 0.8025 - val_loss: 0.4542 - val_accuracy: 0.8150\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.4749 - accuracy: 0.8065 - val_loss: 0.4412 - val_accuracy: 0.8230\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.4737 - accuracy: 0.8007 - val_loss: 0.4417 - val_accuracy: 0.8200\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.4724 - accuracy: 0.8015 - val_loss: 0.4443 - val_accuracy: 0.8315\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.4720 - accuracy: 0.8048 - val_loss: 0.4395 - val_accuracy: 0.8335\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.4722 - accuracy: 0.8007 - val_loss: 0.4823 - val_accuracy: 0.8205\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.4724 - accuracy: 0.8022 - val_loss: 0.4512 - val_accuracy: 0.8315\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.4725 - accuracy: 0.8048 - val_loss: 0.4394 - val_accuracy: 0.8230\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.4707 - accuracy: 0.8033 - val_loss: 0.4535 - val_accuracy: 0.8300\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.4706 - accuracy: 0.8042 - val_loss: 0.4559 - val_accuracy: 0.8145\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.4692 - accuracy: 0.8048 - val_loss: 0.4453 - val_accuracy: 0.8215\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.4693 - accuracy: 0.8050 - val_loss: 0.4408 - val_accuracy: 0.8230\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.4695 - accuracy: 0.8048 - val_loss: 0.4385 - val_accuracy: 0.8215\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.4678 - accuracy: 0.8030 - val_loss: 0.4410 - val_accuracy: 0.8165\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.4684 - accuracy: 0.8057 - val_loss: 0.4441 - val_accuracy: 0.8310\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.4701 - accuracy: 0.8052 - val_loss: 0.4468 - val_accuracy: 0.8125\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.4682 - accuracy: 0.8065 - val_loss: 0.4619 - val_accuracy: 0.8225\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.4680 - accuracy: 0.8045 - val_loss: 0.4385 - val_accuracy: 0.8265\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.4671 - accuracy: 0.8073 - val_loss: 0.4413 - val_accuracy: 0.8270\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.4685 - accuracy: 0.8057 - val_loss: 0.4350 - val_accuracy: 0.8225\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.4666 - accuracy: 0.8060 - val_loss: 0.4337 - val_accuracy: 0.8250\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.4670 - accuracy: 0.8050 - val_loss: 0.4342 - val_accuracy: 0.8190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|    | 16/30 [08:22<06:30, 27.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 20.0085 - accuracy: 0.7990 - val_loss: 9.8170 - val_accuracy: 0.8090\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 5.6802 - accuracy: 0.7970 - val_loss: 2.8906 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 1.6927 - accuracy: 0.7967 - val_loss: 0.8744 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5273 - accuracy: 0.7967 - val_loss: 0.2876 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.1926 - accuracy: 0.7967 - val_loss: 0.1237 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.1020 - accuracy: 0.7967 - val_loss: 0.0819 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.0800 - accuracy: 0.7967 - val_loss: 0.0727 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.0755 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 17/30 [08:45<05:44, 26.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 19.9775 - accuracy: 0.7865 - val_loss: 9.9160 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 5.7702 - accuracy: 0.7967 - val_loss: 2.9588 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.7399 - accuracy: 0.7967 - val_loss: 0.9041 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5465 - accuracy: 0.7967 - val_loss: 0.2988 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.1996 - accuracy: 0.7967 - val_loss: 0.1276 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.1042 - accuracy: 0.7967 - val_loss: 0.0832 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.0806 - accuracy: 0.7967 - val_loss: 0.0730 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.0756 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 18/30 [09:27<06:15, 31.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 22.7524 - accuracy: 0.7910 - val_loss: 10.6173 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 6.3410 - accuracy: 0.8068 - val_loss: 3.5721 - val_accuracy: 0.8235\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 2.4559 - accuracy: 0.8125 - val_loss: 1.6279 - val_accuracy: 0.8345\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 1.2603 - accuracy: 0.8120 - val_loss: 0.9403 - val_accuracy: 0.8100\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.7998 - accuracy: 0.8153 - val_loss: 0.6538 - val_accuracy: 0.8120\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.6116 - accuracy: 0.8152 - val_loss: 0.5415 - val_accuracy: 0.8365\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5355 - accuracy: 0.8202 - val_loss: 0.4867 - val_accuracy: 0.8250\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5074 - accuracy: 0.8218 - val_loss: 0.4852 - val_accuracy: 0.8525\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.4953 - accuracy: 0.8280 - val_loss: 0.4657 - val_accuracy: 0.8495\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.4840 - accuracy: 0.8305 - val_loss: 0.4684 - val_accuracy: 0.8535\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.4843 - accuracy: 0.8305 - val_loss: 0.4817 - val_accuracy: 0.8565\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.4801 - accuracy: 0.8347 - val_loss: 0.4686 - val_accuracy: 0.8530\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.4774 - accuracy: 0.8325 - val_loss: 0.4373 - val_accuracy: 0.8565\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.4688 - accuracy: 0.8418 - val_loss: 0.4586 - val_accuracy: 0.8290\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.4663 - accuracy: 0.8402 - val_loss: 0.4382 - val_accuracy: 0.8450\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4648 - accuracy: 0.8433 - val_loss: 0.4343 - val_accuracy: 0.8575\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.4593 - accuracy: 0.8467 - val_loss: 0.4263 - val_accuracy: 0.8570\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.4582 - accuracy: 0.8417 - val_loss: 0.4460 - val_accuracy: 0.8650\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.4564 - accuracy: 0.8415 - val_loss: 0.4242 - val_accuracy: 0.8645\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.4555 - accuracy: 0.8432 - val_loss: 0.4253 - val_accuracy: 0.8565\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.4504 - accuracy: 0.8467 - val_loss: 0.4259 - val_accuracy: 0.8595\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.4507 - accuracy: 0.8453 - val_loss: 0.4255 - val_accuracy: 0.8590\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.4523 - accuracy: 0.8408 - val_loss: 0.4438 - val_accuracy: 0.8380\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.4491 - accuracy: 0.8457 - val_loss: 0.4266 - val_accuracy: 0.8505\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.4535 - accuracy: 0.8447 - val_loss: 0.4294 - val_accuracy: 0.8610\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.4468 - accuracy: 0.8467 - val_loss: 0.4392 - val_accuracy: 0.8355\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.4461 - accuracy: 0.8468 - val_loss: 0.4136 - val_accuracy: 0.8585\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.4370 - accuracy: 0.8502 - val_loss: 0.4264 - val_accuracy: 0.8645\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.4418 - accuracy: 0.8473 - val_loss: 0.4326 - val_accuracy: 0.8585\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.4484 - accuracy: 0.8468 - val_loss: 0.4124 - val_accuracy: 0.8575\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.4472 - accuracy: 0.8427 - val_loss: 0.4094 - val_accuracy: 0.8640\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.4430 - accuracy: 0.8502 - val_loss: 0.4151 - val_accuracy: 0.8550\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.4374 - accuracy: 0.8512 - val_loss: 0.4119 - val_accuracy: 0.8570\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.4385 - accuracy: 0.8508 - val_loss: 0.4121 - val_accuracy: 0.8560\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.4502 - accuracy: 0.8430 - val_loss: 0.4270 - val_accuracy: 0.8565\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.4362 - accuracy: 0.8510 - val_loss: 0.4121 - val_accuracy: 0.8655\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.4338 - accuracy: 0.8527 - val_loss: 0.4154 - val_accuracy: 0.8660\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.4351 - accuracy: 0.8520 - val_loss: 0.4112 - val_accuracy: 0.8635\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.4314 - accuracy: 0.8543 - val_loss: 0.4196 - val_accuracy: 0.8600\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.4344 - accuracy: 0.8515 - val_loss: 0.4301 - val_accuracy: 0.8580\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.4301 - accuracy: 0.8518 - val_loss: 0.4012 - val_accuracy: 0.8625\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.4320 - accuracy: 0.8505 - val_loss: 0.4490 - val_accuracy: 0.8520\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.4297 - accuracy: 0.8512 - val_loss: 0.4033 - val_accuracy: 0.8620\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.4367 - accuracy: 0.8463 - val_loss: 0.4246 - val_accuracy: 0.8600\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.4348 - accuracy: 0.8475 - val_loss: 0.3971 - val_accuracy: 0.8620\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.4296 - accuracy: 0.8550 - val_loss: 0.4056 - val_accuracy: 0.8650\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.4295 - accuracy: 0.8517 - val_loss: 0.3994 - val_accuracy: 0.8600\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.4307 - accuracy: 0.8488 - val_loss: 0.3970 - val_accuracy: 0.8625\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.4276 - accuracy: 0.8517 - val_loss: 0.4222 - val_accuracy: 0.8625\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.4458 - accuracy: 0.8413 - val_loss: 0.4022 - val_accuracy: 0.8605\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.4278 - accuracy: 0.8543 - val_loss: 0.4592 - val_accuracy: 0.8400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 19/30 [09:56<05:35, 30.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 5.6459 - accuracy: 0.7940 - val_loss: 1.3460 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 0.5580 - accuracy: 0.7967 - val_loss: 0.1887 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.1229 - accuracy: 0.7967 - val_loss: 0.0849 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.0808 - accuracy: 0.7967 - val_loss: 0.0726 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.0755 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0717 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.0750 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0715 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0750 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 20/30 [10:24<04:58, 29.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 6.0285 - accuracy: 0.7955 - val_loss: 1.2293 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 0.4646 - accuracy: 0.7967 - val_loss: 0.1361 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 0.0957 - accuracy: 0.7967 - val_loss: 0.0742 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.0758 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0715 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0716 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0718 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0750 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0750 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 21/30 [11:07<05:01, 33.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 22.4787 - accuracy: 0.7935 - val_loss: 10.1099 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 5.7236 - accuracy: 0.7967 - val_loss: 2.9367 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.8275 - accuracy: 0.7967 - val_loss: 1.0660 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.7123 - accuracy: 0.7967 - val_loss: 0.4476 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.3158 - accuracy: 0.7967 - val_loss: 0.2110 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.1620 - accuracy: 0.7967 - val_loss: 0.1199 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.1039 - accuracy: 0.7967 - val_loss: 0.0862 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0836 - accuracy: 0.7967 - val_loss: 0.0752 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.0772 - accuracy: 0.7967 - val_loss: 0.0723 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0753 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 22/30 [11:50<04:51, 36.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 7.0284 - accuracy: 0.7915 - val_loss: 1.8807 - val_accuracy: 0.8100\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 0.9997 - accuracy: 0.7968 - val_loss: 0.5881 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.5534 - accuracy: 0.7972 - val_loss: 0.5132 - val_accuracy: 0.8090\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.5210 - accuracy: 0.7970 - val_loss: 0.5007 - val_accuracy: 0.8215\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.5112 - accuracy: 0.7982 - val_loss: 0.5021 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7995 - val_loss: 0.5045 - val_accuracy: 0.8210\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.5007 - accuracy: 0.8003 - val_loss: 0.4726 - val_accuracy: 0.8150\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.4967 - accuracy: 0.8005 - val_loss: 0.4644 - val_accuracy: 0.8240\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.4951 - accuracy: 0.8003 - val_loss: 0.4594 - val_accuracy: 0.8185\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.4917 - accuracy: 0.8003 - val_loss: 0.4624 - val_accuracy: 0.8090\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.4884 - accuracy: 0.8037 - val_loss: 0.4694 - val_accuracy: 0.8165\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.4876 - accuracy: 0.8050 - val_loss: 0.4613 - val_accuracy: 0.8270\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.4856 - accuracy: 0.8037 - val_loss: 0.4495 - val_accuracy: 0.8265\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.4839 - accuracy: 0.8010 - val_loss: 0.4516 - val_accuracy: 0.8145\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.4820 - accuracy: 0.8040 - val_loss: 0.4500 - val_accuracy: 0.8155\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.4821 - accuracy: 0.8025 - val_loss: 0.4469 - val_accuracy: 0.8235\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.4789 - accuracy: 0.8045 - val_loss: 0.4631 - val_accuracy: 0.8215\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.4789 - accuracy: 0.8045 - val_loss: 0.4454 - val_accuracy: 0.8210\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.4766 - accuracy: 0.8042 - val_loss: 0.4410 - val_accuracy: 0.8240\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.4777 - accuracy: 0.8040 - val_loss: 0.4415 - val_accuracy: 0.8240\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.4753 - accuracy: 0.8055 - val_loss: 0.4475 - val_accuracy: 0.8165\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.4763 - accuracy: 0.8017 - val_loss: 0.4678 - val_accuracy: 0.8085\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.4759 - accuracy: 0.8052 - val_loss: 0.4549 - val_accuracy: 0.8125\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.4752 - accuracy: 0.8022 - val_loss: 0.4384 - val_accuracy: 0.8250\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.4731 - accuracy: 0.8033 - val_loss: 0.4456 - val_accuracy: 0.8165\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.4729 - accuracy: 0.8028 - val_loss: 0.4641 - val_accuracy: 0.8160\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.4734 - accuracy: 0.8023 - val_loss: 0.4424 - val_accuracy: 0.8300\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.4708 - accuracy: 0.8063 - val_loss: 0.4432 - val_accuracy: 0.8145\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.4729 - accuracy: 0.8045 - val_loss: 0.4367 - val_accuracy: 0.8235\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.4706 - accuracy: 0.8047 - val_loss: 0.4366 - val_accuracy: 0.8215\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.4705 - accuracy: 0.8052 - val_loss: 0.4367 - val_accuracy: 0.8290\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.4696 - accuracy: 0.8022 - val_loss: 0.4393 - val_accuracy: 0.8180\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.4695 - accuracy: 0.8045 - val_loss: 0.4685 - val_accuracy: 0.8185\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.4706 - accuracy: 0.8023 - val_loss: 0.4386 - val_accuracy: 0.8180\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.4683 - accuracy: 0.8057 - val_loss: 0.4379 - val_accuracy: 0.8185\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.4687 - accuracy: 0.8017 - val_loss: 0.4430 - val_accuracy: 0.8195\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.4686 - accuracy: 0.8020 - val_loss: 0.4434 - val_accuracy: 0.8260\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.4691 - accuracy: 0.8040 - val_loss: 0.4329 - val_accuracy: 0.8330\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.4684 - accuracy: 0.8077 - val_loss: 0.4605 - val_accuracy: 0.8210\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.4681 - accuracy: 0.8068 - val_loss: 0.4368 - val_accuracy: 0.8195\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.4679 - accuracy: 0.8042 - val_loss: 0.4384 - val_accuracy: 0.8155\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.4679 - accuracy: 0.8030 - val_loss: 0.4362 - val_accuracy: 0.8300\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.4666 - accuracy: 0.8068 - val_loss: 0.4344 - val_accuracy: 0.8205\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.4659 - accuracy: 0.8068 - val_loss: 0.4616 - val_accuracy: 0.8215\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.4672 - accuracy: 0.8038 - val_loss: 0.4376 - val_accuracy: 0.8320\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.4684 - accuracy: 0.8055 - val_loss: 0.4429 - val_accuracy: 0.8130\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.4683 - accuracy: 0.8053 - val_loss: 0.4377 - val_accuracy: 0.8270\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.4673 - accuracy: 0.8062 - val_loss: 0.4334 - val_accuracy: 0.8270\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.4658 - accuracy: 0.8040 - val_loss: 0.4534 - val_accuracy: 0.8190\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.4671 - accuracy: 0.8053 - val_loss: 0.4318 - val_accuracy: 0.8325\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.4666 - accuracy: 0.8027 - val_loss: 0.4316 - val_accuracy: 0.8280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|  | 23/30 [12:19<04:00, 34.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 24.4390 - accuracy: 0.7945 - val_loss: 15.4665 - val_accuracy: 0.8275\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 10.4994 - accuracy: 0.8100 - val_loss: 6.6601 - val_accuracy: 0.8175\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 4.5614 - accuracy: 0.8000 - val_loss: 2.9322 - val_accuracy: 0.8100\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 2.0854 - accuracy: 0.7980 - val_loss: 1.4178 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 1.1005 - accuracy: 0.7967 - val_loss: 0.8334 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.7267 - accuracy: 0.7967 - val_loss: 0.6156 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5841 - accuracy: 0.7967 - val_loss: 0.5287 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5288 - accuracy: 0.7967 - val_loss: 0.4994 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5111 - accuracy: 0.7967 - val_loss: 0.4906 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.5068 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4886 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4894 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4884 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4884 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4901 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 24/30 [12:44<03:09, 31.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 22.5063 - accuracy: 0.7950 - val_loss: 10.3354 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 6.0341 - accuracy: 0.7967 - val_loss: 3.2625 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 2.0974 - accuracy: 0.7967 - val_loss: 1.2694 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.8570 - accuracy: 0.7967 - val_loss: 0.5412 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.3769 - accuracy: 0.7967 - val_loss: 0.2468 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.1837 - accuracy: 0.7967 - val_loss: 0.1311 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.1105 - accuracy: 0.7967 - val_loss: 0.0894 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0853 - accuracy: 0.7967 - val_loss: 0.0762 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0775 - accuracy: 0.7967 - val_loss: 0.0725 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0754 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 25/30 [13:26<02:53, 34.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 21.6235 - accuracy: 0.7865 - val_loss: 9.5966 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 5.4384 - accuracy: 0.7967 - val_loss: 2.8064 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.7590 - accuracy: 0.7967 - val_loss: 1.0359 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.6964 - accuracy: 0.7967 - val_loss: 0.4403 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.3117 - accuracy: 0.7967 - val_loss: 0.2087 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.1606 - accuracy: 0.7967 - val_loss: 0.1188 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.1034 - accuracy: 0.7967 - val_loss: 0.0864 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0834 - accuracy: 0.7967 - val_loss: 0.0751 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0771 - accuracy: 0.7967 - val_loss: 0.0719 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0753 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0713 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 26/30 [14:08<02:27, 36.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 22.5613 - accuracy: 0.8072 - val_loss: 10.2944 - val_accuracy: 0.8120\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 5.9094 - accuracy: 0.7973 - val_loss: 3.1054 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 1.9614 - accuracy: 0.7967 - val_loss: 1.1662 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.7865 - accuracy: 0.7967 - val_loss: 0.4988 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.3514 - accuracy: 0.7967 - val_loss: 0.2338 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.1770 - accuracy: 0.7967 - val_loss: 0.1283 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.1094 - accuracy: 0.7967 - val_loss: 0.0894 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0854 - accuracy: 0.7967 - val_loss: 0.0762 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0777 - accuracy: 0.7967 - val_loss: 0.0723 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0755 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0714 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0718 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0708 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0712 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0749 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0711 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0710 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0748 - accuracy: 0.7967 - val_loss: 0.0709 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0747 - accuracy: 0.7967 - val_loss: 0.0715 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 27/30 [14:39<01:44, 34.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 7.0578 - accuracy: 0.7923 - val_loss: 2.8125 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 1.6331 - accuracy: 0.7967 - val_loss: 0.9275 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.7271 - accuracy: 0.7967 - val_loss: 0.5776 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5488 - accuracy: 0.7967 - val_loss: 0.5032 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.5127 - accuracy: 0.7967 - val_loss: 0.4947 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.5069 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4888 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4885 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4893 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4890 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.5049 - accuracy: 0.7967 - val_loss: 0.4930 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5047 - accuracy: 0.7967 - val_loss: 0.4888 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4891 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.5050 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5050 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4890 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 28/30 [15:05<01:04, 32.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 26.9948 - accuracy: 0.7680 - val_loss: 15.5862 - val_accuracy: 0.8095\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 10.1946 - accuracy: 0.7965 - val_loss: 6.2465 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 4.2526 - accuracy: 0.7967 - val_loss: 2.7410 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 1.9689 - accuracy: 0.7967 - val_loss: 1.3583 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 1.0585 - accuracy: 0.7967 - val_loss: 0.8038 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 0s - loss: 0.6990 - accuracy: 0.7967 - val_loss: 0.5920 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5678 - accuracy: 0.7967 - val_loss: 0.5202 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5247 - accuracy: 0.7967 - val_loss: 0.4982 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5116 - accuracy: 0.7967 - val_loss: 0.4914 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.5073 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5061 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4904 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4891 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4899 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4880 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4875 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4886 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5050 - accuracy: 0.7967 - val_loss: 0.4903 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4892 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 29/30 [15:30<00:30, 30.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 2s - loss: 7.9433 - accuracy: 0.7917 - val_loss: 3.0023 - val_accuracy: 0.8085\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 1.6704 - accuracy: 0.7972 - val_loss: 0.8963 - val_accuracy: 0.8095\n",
            "Epoch 3/51\n",
            "188/188 - 0s - loss: 0.6993 - accuracy: 0.7967 - val_loss: 0.5563 - val_accuracy: 0.8095\n",
            "Epoch 4/51\n",
            "188/188 - 0s - loss: 0.5358 - accuracy: 0.7967 - val_loss: 0.4963 - val_accuracy: 0.8095\n",
            "Epoch 5/51\n",
            "188/188 - 0s - loss: 0.5094 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.5060 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 7/51\n",
            "188/188 - 0s - loss: 0.5062 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 8/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4890 - val_accuracy: 0.8095\n",
            "Epoch 13/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 15/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n",
            "Epoch 16/51\n",
            "188/188 - 0s - loss: 0.5057 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.8095\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4887 - val_accuracy: 0.8095\n",
            "Epoch 18/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4889 - val_accuracy: 0.8095\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.5058 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.5059 - accuracy: 0.7967 - val_loss: 0.4890 - val_accuracy: 0.8095\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.5051 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 22/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4879 - val_accuracy: 0.8095\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 27/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4888 - val_accuracy: 0.8095\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.5050 - accuracy: 0.7967 - val_loss: 0.4881 - val_accuracy: 0.8095\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4882 - val_accuracy: 0.8095\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 34/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.5052 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.5055 - accuracy: 0.7967 - val_loss: 0.4871 - val_accuracy: 0.8095\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4872 - val_accuracy: 0.8095\n",
            "Epoch 43/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4893 - val_accuracy: 0.8095\n",
            "Epoch 44/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
            "Epoch 45/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4873 - val_accuracy: 0.8095\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.5053 - accuracy: 0.7967 - val_loss: 0.4876 - val_accuracy: 0.8095\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4883 - val_accuracy: 0.8095\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4877 - val_accuracy: 0.8095\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.5054 - accuracy: 0.7967 - val_loss: 0.4874 - val_accuracy: 0.8095\n",
            "Epoch 51/51\n",
            "188/188 - 0s - loss: 0.5056 - accuracy: 0.7967 - val_loss: 0.4870 - val_accuracy: 0.8095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [16:12<00:00, 32.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the results data frame\n",
        "scan_object.data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "Y_7Q5pukV7HD",
        "outputId": "3ec5a77f-30f8-40d1-ac26-1012fe937f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             start              end   duration  round_epochs      loss  \\\n",
              "0  11/07/22-132922  11/07/22-133005  42.852551            51  0.464736   \n",
              "1  11/07/22-133006  11/07/22-133030  24.258456            51  0.505315   \n",
              "2  11/07/22-133030  11/07/22-133058  27.890851            51  0.471682   \n",
              "3  11/07/22-133059  11/07/22-133126  27.440482            51  0.505352   \n",
              "4  11/07/22-133126  11/07/22-133209  42.646061            51  0.074764   \n",
              "\n",
              "   accuracy  val_loss  val_accuracy    lr  first_neuron  ...  batch_size  \\\n",
              "0  0.808500  0.436373        0.8325  0.10            64  ...          32   \n",
              "1  0.796667  0.487601        0.8095  0.01            32  ...          64   \n",
              "2  0.804000  0.448358        0.8300  0.01            32  ...          32   \n",
              "3  0.796667  0.488024        0.8095  0.10            32  ...          32   \n",
              "4  0.796667  0.070856        0.8095  0.10            64  ...          32   \n",
              "\n",
              "   epochs  dropout  weight_regulizer emb_output_dims        shape optimizer  \\\n",
              "0     100      0.0      GlorotNormal            None  long_funnel     Nadam   \n",
              "1     100      0.0          HeNormal            None        brick    Adamax   \n",
              "2     100      0.5          HeNormal            None        brick      Adam   \n",
              "3     100      0.0      GlorotNormal            None        brick      Adam   \n",
              "4     100      0.5          HeNormal            None        brick     Nadam   \n",
              "\n",
              "                losses activation last_activation  \n",
              "0  binary_crossentropy        elu         sigmoid  \n",
              "1  binary_crossentropy       relu         sigmoid  \n",
              "2  binary_crossentropy        elu         sigmoid  \n",
              "3  binary_crossentropy       relu         sigmoid  \n",
              "4              logcosh        elu         sigmoid  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60a1ae8f-e831-47f0-8ad9-8163860219b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>lr</th>\n",
              "      <th>first_neuron</th>\n",
              "      <th>...</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>dropout</th>\n",
              "      <th>weight_regulizer</th>\n",
              "      <th>emb_output_dims</th>\n",
              "      <th>shape</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>losses</th>\n",
              "      <th>activation</th>\n",
              "      <th>last_activation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/07/22-132922</td>\n",
              "      <td>11/07/22-133005</td>\n",
              "      <td>42.852551</td>\n",
              "      <td>51</td>\n",
              "      <td>0.464736</td>\n",
              "      <td>0.808500</td>\n",
              "      <td>0.436373</td>\n",
              "      <td>0.8325</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11/07/22-133006</td>\n",
              "      <td>11/07/22-133030</td>\n",
              "      <td>24.258456</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505315</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487601</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11/07/22-133030</td>\n",
              "      <td>11/07/22-133058</td>\n",
              "      <td>27.890851</td>\n",
              "      <td>51</td>\n",
              "      <td>0.471682</td>\n",
              "      <td>0.804000</td>\n",
              "      <td>0.448358</td>\n",
              "      <td>0.8300</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/07/22-133059</td>\n",
              "      <td>11/07/22-133126</td>\n",
              "      <td>27.440482</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505352</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.488024</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11/07/22-133126</td>\n",
              "      <td>11/07/22-133209</td>\n",
              "      <td>42.646061</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074764</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070856</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60a1ae8f-e831-47f0-8ad9-8163860219b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60a1ae8f-e831-47f0-8ad9-8163860219b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60a1ae8f-e831-47f0-8ad9-8163860219b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing epoch entropy values for each round\n",
        "scan_object.learning_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "hIqW3Epq8F3P",
        "outputId": "08d3f292-71fb-4646-f005-1cd1dd25bed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        loss      accuracy\n",
              "0   0.079785  3.386055e-05\n",
              "1   0.028428  1.148583e-06\n",
              "2   0.050637  2.858149e-05\n",
              "3   0.064434  1.631470e-06\n",
              "4   0.034404  3.667241e-09\n",
              "5   0.079344  4.206712e-10\n",
              "6   0.024558  1.056106e-06\n",
              "7   0.048367  3.080778e-05\n",
              "8   0.064597  2.521820e-06\n",
              "9   0.184279  5.480058e-07\n",
              "10  0.148726  5.179015e-07\n",
              "11  0.079835  3.552521e-07\n",
              "12  0.052032  3.321073e-05\n",
              "13  0.024298  3.820815e-06\n",
              "14  0.028267  3.078569e-07\n",
              "15  0.046703  3.258301e-05\n",
              "16  0.027962  1.217909e-07\n",
              "17  0.026813  1.579043e-06\n",
              "18  0.052322  6.347843e-05\n",
              "19  0.212747  1.079366e-07\n",
              "20  0.263844  2.063471e-08\n",
              "21  0.033816  1.522751e-07\n",
              "22  0.081235  2.617479e-05\n",
              "23  0.020321  6.641613e-06\n",
              "24  0.030796  4.212706e-08\n",
              "25  0.036129  1.579043e-06\n",
              "26  0.031896  9.725862e-07\n",
              "27  0.047109  2.854359e-07\n",
              "28  0.027818  1.275556e-05\n",
              "29  0.056156  2.503891e-07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce44d3fd-a77f-43f8-b848-d48fe6351612\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.079785</td>\n",
              "      <td>3.386055e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.028428</td>\n",
              "      <td>1.148583e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.050637</td>\n",
              "      <td>2.858149e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.064434</td>\n",
              "      <td>1.631470e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.034404</td>\n",
              "      <td>3.667241e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.079344</td>\n",
              "      <td>4.206712e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.024558</td>\n",
              "      <td>1.056106e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.048367</td>\n",
              "      <td>3.080778e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.064597</td>\n",
              "      <td>2.521820e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.184279</td>\n",
              "      <td>5.480058e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.148726</td>\n",
              "      <td>5.179015e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.079835</td>\n",
              "      <td>3.552521e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.052032</td>\n",
              "      <td>3.321073e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.024298</td>\n",
              "      <td>3.820815e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.028267</td>\n",
              "      <td>3.078569e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.046703</td>\n",
              "      <td>3.258301e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.027962</td>\n",
              "      <td>1.217909e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.026813</td>\n",
              "      <td>1.579043e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.052322</td>\n",
              "      <td>6.347843e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.212747</td>\n",
              "      <td>1.079366e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.263844</td>\n",
              "      <td>2.063471e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.033816</td>\n",
              "      <td>1.522751e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.081235</td>\n",
              "      <td>2.617479e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.020321</td>\n",
              "      <td>6.641613e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.030796</td>\n",
              "      <td>4.212706e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.036129</td>\n",
              "      <td>1.579043e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.031896</td>\n",
              "      <td>9.725862e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.047109</td>\n",
              "      <td>2.854359e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.027818</td>\n",
              "      <td>1.275556e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.056156</td>\n",
              "      <td>2.503891e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce44d3fd-a77f-43f8-b848-d48fe6351612')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce44d3fd-a77f-43f8-b848-d48fe6351612 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce44d3fd-a77f-43f8-b848-d48fe6351612');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access the summary details\n",
        "scan_object.details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twkXVmWn8Hnc",
        "outputId": "a10a5d87-f3db-4881-da74-f3dd5f1061a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "experiment_name                 churn\n",
              "random_method                 quantum\n",
              "reduction_method                 None\n",
              "reduction_interval                 50\n",
              "reduction_window                   20\n",
              "reduction_threshold               0.2\n",
              "reduction_metric              val_acc\n",
              "experiment_id            110722132915\n",
              "complete_time          11/07/22/13:45\n",
              "x_shape                    (8000, 13)\n",
              "y_shape                       (8000,)\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the saved weights for models\n",
        "scan_object.saved_weights"
      ],
      "metadata": {
        "id": "LgsWSFoH8b6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use Scan object as input\n",
        "analyze_object = ta.Analyze(scan_object)\n",
        "\n",
        "# access the dataframe with the results\n",
        "analyze_object.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7VKU3yyo-ki7",
        "outputId": "ed82cfec-9bab-433d-b551-394770e4106c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              start              end   duration  round_epochs      loss  \\\n",
              "0   11/07/22-132922  11/07/22-133005  42.852551            51  0.464736   \n",
              "1   11/07/22-133006  11/07/22-133030  24.258456            51  0.505315   \n",
              "2   11/07/22-133030  11/07/22-133058  27.890851            51  0.471682   \n",
              "3   11/07/22-133059  11/07/22-133126  27.440482            51  0.505352   \n",
              "4   11/07/22-133126  11/07/22-133209  42.646061            51  0.074764   \n",
              "5   11/07/22-133209  11/07/22-133237  27.782334            51  0.505402   \n",
              "6   11/07/22-133238  11/07/22-133302  24.052564            51  0.074719   \n",
              "7   11/07/22-133302  11/07/22-133345  42.660599            51  0.465356   \n",
              "8   11/07/22-133345  11/07/22-133413  27.923140            51  0.505603   \n",
              "9   11/07/22-133413  11/07/22-133455  41.843487            51  0.074689   \n",
              "10  11/07/22-133455  11/07/22-133520  24.343301            51  0.074750   \n",
              "11  11/07/22-133520  11/07/22-133603  42.758983            51  0.505365   \n",
              "12  11/07/22-133603  11/07/22-133629  26.394318            51  0.469266   \n",
              "13  11/07/22-133630  11/07/22-133653  23.912782            51  0.505799   \n",
              "14  11/07/22-133654  11/07/22-133717  22.959528            51  0.074702   \n",
              "15  11/07/22-133717  11/07/22-133744  27.207897            51  0.466995   \n",
              "16  11/07/22-133744  11/07/22-133807  22.965834            51  0.074709   \n",
              "17  11/07/22-133808  11/07/22-133850  41.992130            51  0.074727   \n",
              "18  11/07/22-133850  11/07/22-133919  28.450734            51  0.427834   \n",
              "19  11/07/22-133919  11/07/22-133947  27.923596            51  0.074712   \n",
              "20  11/07/22-133947  11/07/22-134029  41.869665            51  0.074748   \n",
              "21  11/07/22-134029  11/07/22-134112  42.716996            51  0.074711   \n",
              "22  11/07/22-134112  11/07/22-134142  29.324832            51  0.466648   \n",
              "23  11/07/22-134142  11/07/22-134207  24.592016            51  0.505467   \n",
              "24  11/07/22-134207  11/07/22-134249  41.814621            51  0.074733   \n",
              "25  11/07/22-134249  11/07/22-134331  41.877449            51  0.074762   \n",
              "26  11/07/22-134331  11/07/22-134401  30.066855            51  0.074707   \n",
              "27  11/07/22-134402  11/07/22-134427  25.570290            51  0.505127   \n",
              "28  11/07/22-134428  11/07/22-134452  24.992200            51  0.505169   \n",
              "29  11/07/22-134453  11/07/22-134535  41.952977            51  0.505557   \n",
              "\n",
              "    accuracy  val_loss  val_accuracy    lr  first_neuron  ...  batch_size  \\\n",
              "0   0.808500  0.436373        0.8325  0.10            64  ...          32   \n",
              "1   0.796667  0.487601        0.8095  0.01            32  ...          64   \n",
              "2   0.804000  0.448358        0.8300  0.01            32  ...          32   \n",
              "3   0.796667  0.488024        0.8095  0.10            32  ...          32   \n",
              "4   0.796667  0.070856        0.8095  0.10            64  ...          32   \n",
              "5   0.796667  0.487853        0.8095  0.10            64  ...          32   \n",
              "6   0.796667  0.070888        0.8095  0.10            64  ...          32   \n",
              "7   0.804500  0.462804        0.8190  0.01            32  ...          32   \n",
              "8   0.796667  0.488069        0.8095  0.10            32  ...          32   \n",
              "9   0.796667  0.070853        0.8095  0.10            64  ...          32   \n",
              "10  0.796667  0.070869        0.8095  0.01            32  ...          32   \n",
              "11  0.796667  0.487394        0.8095  0.10            64  ...          32   \n",
              "12  0.803833  0.448865        0.8165  0.10            32  ...          32   \n",
              "13  0.796667  0.487087        0.8095  0.10            64  ...          64   \n",
              "14  0.796667  0.070950        0.8095  0.01            32  ...          32   \n",
              "15  0.805000  0.434180        0.8190  0.01            32  ...          32   \n",
              "16  0.796667  0.071087        0.8095  0.01            32  ...          64   \n",
              "17  0.796667  0.070858        0.8095  0.10            32  ...          64   \n",
              "18  0.854333  0.459182        0.8400  0.01            64  ...          32   \n",
              "19  0.796667  0.070884        0.8095  0.01            32  ...          32   \n",
              "20  0.796667  0.070909        0.8095  0.01            64  ...          64   \n",
              "21  0.796667  0.070867        0.8095  0.01            64  ...          64   \n",
              "22  0.802667  0.431633        0.8280  0.10            64  ...          64   \n",
              "23  0.796667  0.487714        0.8095  0.01            32  ...          32   \n",
              "24  0.796667  0.070923        0.8095  0.10            64  ...          32   \n",
              "25  0.796667  0.070880        0.8095  0.01            64  ...          32   \n",
              "26  0.796667  0.071486        0.8095  0.01            64  ...          32   \n",
              "27  0.796667  0.487221        0.8095  0.10            32  ...          64   \n",
              "28  0.796667  0.489250        0.8095  0.10            64  ...          64   \n",
              "29  0.796667  0.486966        0.8095  0.10            64  ...          64   \n",
              "\n",
              "    epochs  dropout  weight_regulizer emb_output_dims        shape optimizer  \\\n",
              "0      100      0.0      GlorotNormal            None  long_funnel     Nadam   \n",
              "1      100      0.0          HeNormal            None        brick    Adamax   \n",
              "2      100      0.5          HeNormal            None        brick      Adam   \n",
              "3      100      0.0      GlorotNormal            None        brick      Adam   \n",
              "4      100      0.5          HeNormal            None        brick     Nadam   \n",
              "5      100      0.5      GlorotNormal            None        brick     Nadam   \n",
              "6      100      0.0          HeNormal            None        brick    Adamax   \n",
              "7      100      0.0          HeNormal            None  long_funnel     Nadam   \n",
              "8      100      0.5      GlorotNormal            None        brick     Nadam   \n",
              "9      100      0.0      GlorotNormal            None        brick    Adamax   \n",
              "10     100      0.5      GlorotNormal            None  long_funnel    Adamax   \n",
              "11     100      0.0      GlorotNormal            None        brick     Nadam   \n",
              "12     100      0.0          HeNormal            None        brick      Adam   \n",
              "13     100      0.0          HeNormal            None  long_funnel    Adamax   \n",
              "14     100      0.0          HeNormal            None  long_funnel    Adamax   \n",
              "15     100      0.0          HeNormal            None  long_funnel     Nadam   \n",
              "16     100      0.0          HeNormal            None  long_funnel    Adamax   \n",
              "17     100      0.0          HeNormal            None  long_funnel    Adamax   \n",
              "18     100      0.5          HeNormal            None  long_funnel      Adam   \n",
              "19     100      0.5      GlorotNormal            None        brick      Adam   \n",
              "20     100      0.0      GlorotNormal            None        brick      Adam   \n",
              "21     100      0.5          HeNormal            None  long_funnel     Nadam   \n",
              "22     100      0.5      GlorotNormal            None        brick     Nadam   \n",
              "23     100      0.5          HeNormal            None  long_funnel    Adamax   \n",
              "24     100      0.5          HeNormal            None  long_funnel      Adam   \n",
              "25     100      0.0          HeNormal            None        brick      Adam   \n",
              "26     100      0.5          HeNormal            None  long_funnel     Nadam   \n",
              "27     100      0.5      GlorotNormal            None        brick    Adamax   \n",
              "28     100      0.5          HeNormal            None  long_funnel    Adamax   \n",
              "29     100      0.0      GlorotNormal            None  long_funnel    Adamax   \n",
              "\n",
              "                 losses activation last_activation  \n",
              "0   binary_crossentropy        elu         sigmoid  \n",
              "1   binary_crossentropy       relu         sigmoid  \n",
              "2   binary_crossentropy        elu         sigmoid  \n",
              "3   binary_crossentropy       relu         sigmoid  \n",
              "4               logcosh        elu         sigmoid  \n",
              "5   binary_crossentropy       relu         sigmoid  \n",
              "6               logcosh        elu         sigmoid  \n",
              "7   binary_crossentropy        elu         sigmoid  \n",
              "8   binary_crossentropy       relu         sigmoid  \n",
              "9               logcosh        elu         sigmoid  \n",
              "10              logcosh        elu         sigmoid  \n",
              "11  binary_crossentropy       relu         sigmoid  \n",
              "12  binary_crossentropy        elu         sigmoid  \n",
              "13  binary_crossentropy        elu         sigmoid  \n",
              "14              logcosh       relu         sigmoid  \n",
              "15  binary_crossentropy        elu         sigmoid  \n",
              "16              logcosh        elu         sigmoid  \n",
              "17              logcosh        elu         sigmoid  \n",
              "18  binary_crossentropy       relu         sigmoid  \n",
              "19              logcosh        elu         sigmoid  \n",
              "20              logcosh        elu         sigmoid  \n",
              "21              logcosh       relu         sigmoid  \n",
              "22  binary_crossentropy        elu         sigmoid  \n",
              "23  binary_crossentropy        elu         sigmoid  \n",
              "24              logcosh       relu         sigmoid  \n",
              "25              logcosh       relu         sigmoid  \n",
              "26              logcosh        elu         sigmoid  \n",
              "27  binary_crossentropy        elu         sigmoid  \n",
              "28  binary_crossentropy       relu         sigmoid  \n",
              "29  binary_crossentropy        elu         sigmoid  \n",
              "\n",
              "[30 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22f7d9c1-a5a0-4655-bfc2-48b06b9cb66d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>lr</th>\n",
              "      <th>first_neuron</th>\n",
              "      <th>...</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>dropout</th>\n",
              "      <th>weight_regulizer</th>\n",
              "      <th>emb_output_dims</th>\n",
              "      <th>shape</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>losses</th>\n",
              "      <th>activation</th>\n",
              "      <th>last_activation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/07/22-132922</td>\n",
              "      <td>11/07/22-133005</td>\n",
              "      <td>42.852551</td>\n",
              "      <td>51</td>\n",
              "      <td>0.464736</td>\n",
              "      <td>0.808500</td>\n",
              "      <td>0.436373</td>\n",
              "      <td>0.8325</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11/07/22-133006</td>\n",
              "      <td>11/07/22-133030</td>\n",
              "      <td>24.258456</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505315</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487601</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11/07/22-133030</td>\n",
              "      <td>11/07/22-133058</td>\n",
              "      <td>27.890851</td>\n",
              "      <td>51</td>\n",
              "      <td>0.471682</td>\n",
              "      <td>0.804000</td>\n",
              "      <td>0.448358</td>\n",
              "      <td>0.8300</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/07/22-133059</td>\n",
              "      <td>11/07/22-133126</td>\n",
              "      <td>27.440482</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505352</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.488024</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11/07/22-133126</td>\n",
              "      <td>11/07/22-133209</td>\n",
              "      <td>42.646061</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074764</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070856</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11/07/22-133209</td>\n",
              "      <td>11/07/22-133237</td>\n",
              "      <td>27.782334</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505402</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487853</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11/07/22-133238</td>\n",
              "      <td>11/07/22-133302</td>\n",
              "      <td>24.052564</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074719</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070888</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11/07/22-133302</td>\n",
              "      <td>11/07/22-133345</td>\n",
              "      <td>42.660599</td>\n",
              "      <td>51</td>\n",
              "      <td>0.465356</td>\n",
              "      <td>0.804500</td>\n",
              "      <td>0.462804</td>\n",
              "      <td>0.8190</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11/07/22-133345</td>\n",
              "      <td>11/07/22-133413</td>\n",
              "      <td>27.923140</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505603</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.488069</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11/07/22-133413</td>\n",
              "      <td>11/07/22-133455</td>\n",
              "      <td>41.843487</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074689</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070853</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11/07/22-133455</td>\n",
              "      <td>11/07/22-133520</td>\n",
              "      <td>24.343301</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074750</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070869</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11/07/22-133520</td>\n",
              "      <td>11/07/22-133603</td>\n",
              "      <td>42.758983</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505365</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487394</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11/07/22-133603</td>\n",
              "      <td>11/07/22-133629</td>\n",
              "      <td>26.394318</td>\n",
              "      <td>51</td>\n",
              "      <td>0.469266</td>\n",
              "      <td>0.803833</td>\n",
              "      <td>0.448865</td>\n",
              "      <td>0.8165</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11/07/22-133630</td>\n",
              "      <td>11/07/22-133653</td>\n",
              "      <td>23.912782</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505799</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487087</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11/07/22-133654</td>\n",
              "      <td>11/07/22-133717</td>\n",
              "      <td>22.959528</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074702</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070950</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11/07/22-133717</td>\n",
              "      <td>11/07/22-133744</td>\n",
              "      <td>27.207897</td>\n",
              "      <td>51</td>\n",
              "      <td>0.466995</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.434180</td>\n",
              "      <td>0.8190</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11/07/22-133744</td>\n",
              "      <td>11/07/22-133807</td>\n",
              "      <td>22.965834</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074709</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.071087</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11/07/22-133808</td>\n",
              "      <td>11/07/22-133850</td>\n",
              "      <td>41.992130</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074727</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070858</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11/07/22-133850</td>\n",
              "      <td>11/07/22-133919</td>\n",
              "      <td>28.450734</td>\n",
              "      <td>51</td>\n",
              "      <td>0.427834</td>\n",
              "      <td>0.854333</td>\n",
              "      <td>0.459182</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>11/07/22-133919</td>\n",
              "      <td>11/07/22-133947</td>\n",
              "      <td>27.923596</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074712</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070884</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>11/07/22-133947</td>\n",
              "      <td>11/07/22-134029</td>\n",
              "      <td>41.869665</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074748</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070909</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>11/07/22-134029</td>\n",
              "      <td>11/07/22-134112</td>\n",
              "      <td>42.716996</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074711</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070867</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>11/07/22-134112</td>\n",
              "      <td>11/07/22-134142</td>\n",
              "      <td>29.324832</td>\n",
              "      <td>51</td>\n",
              "      <td>0.466648</td>\n",
              "      <td>0.802667</td>\n",
              "      <td>0.431633</td>\n",
              "      <td>0.8280</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>11/07/22-134142</td>\n",
              "      <td>11/07/22-134207</td>\n",
              "      <td>24.592016</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505467</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487714</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11/07/22-134207</td>\n",
              "      <td>11/07/22-134249</td>\n",
              "      <td>41.814621</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074733</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070923</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>11/07/22-134249</td>\n",
              "      <td>11/07/22-134331</td>\n",
              "      <td>41.877449</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074762</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070880</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>11/07/22-134331</td>\n",
              "      <td>11/07/22-134401</td>\n",
              "      <td>30.066855</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.071486</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>11/07/22-134402</td>\n",
              "      <td>11/07/22-134427</td>\n",
              "      <td>25.570290</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505127</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487221</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>11/07/22-134428</td>\n",
              "      <td>11/07/22-134452</td>\n",
              "      <td>24.992200</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505169</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.489250</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>11/07/22-134453</td>\n",
              "      <td>11/07/22-134535</td>\n",
              "      <td>41.952977</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505557</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.486966</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>None</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows  21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22f7d9c1-a5a0-4655-bfc2-48b06b9cb66d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22f7d9c1-a5a0-4655-bfc2-48b06b9cb66d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22f7d9c1-a5a0-4655-bfc2-48b06b9cb66d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of rounds in the Scan took to get highest result of accuracy\n",
        "analyze_object.rounds2high('accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pplcAeRQ-vfW",
        "outputId": "29e55cb5-03b3-4ee8-94a8-bed40fa4d594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of rounds\n",
        "analyze_object.rounds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hluqDI58bPS",
        "outputId": "8ddf923d-e0e5-46db-8755-09b0ccff8e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the highest result for accuracy\n",
        "print(round(analyze_object.low('accuracy')*100, 2), '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNcU_90y-m96",
        "outputId": "37aaf230-d792-4d77-e10b-dab2be0d49d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79.67 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the lowest result for loss\n",
        "print(round(analyze_object.low('loss')*100, 2), '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J40_Xq7BbaxR",
        "outputId": "0a9b1bb1-cff0-45b1-d32d-f9e15b09df8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.47 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the highest result for testing accuracy\n",
        "print(round(analyze_object.low('val_accuracy')*100, 2), '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKIwLORr_qJc",
        "outputId": "f6a493f0-ea50-48cb-d2b1-6bf1ff950cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80.95 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the lowest result for testing loss\n",
        "print(round(analyze_object.low('val_loss')*100, 2), '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFdL93smbiC0",
        "outputId": "7b38e512-dac3-4b47-a26f-8c19529cf341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.09 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best paramaters\n",
        "analyze_object.best_params('val_accuracy', ['accuracy', 'loss', 'val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_sX61o1_wPY",
        "outputId": "d39c63bc-768a-4cb0-c63d-21e168d584fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['sigmoid', 28.45073366165161, 32, None, 0.5, '11/07/22-133850',\n",
              "        'Adam', 'binary_crossentropy', 5, 51, 'relu', 64, 'long_funnel',\n",
              "        'HeNormal', '11/07/22-133919', 100, 0.01, 0],\n",
              "       ['sigmoid', 42.85255146026611, 32, None, 0.0, '11/07/22-132922',\n",
              "        'Nadam', 'binary_crossentropy', 2, 51, 'elu', 64, 'long_funnel',\n",
              "        'GlorotNormal', '11/07/22-133005', 100, 0.1, 1],\n",
              "       ['sigmoid', 27.890851497650146, 32, None, 0.5, '11/07/22-133030',\n",
              "        'Adam', 'binary_crossentropy', 5, 51, 'elu', 32, 'brick',\n",
              "        'HeNormal', '11/07/22-133058', 100, 0.01, 2],\n",
              "       ['sigmoid', 29.324832439422607, 64, None, 0.5, '11/07/22-134112',\n",
              "        'Nadam', 'binary_crossentropy', 2, 51, 'elu', 64, 'brick',\n",
              "        'GlorotNormal', '11/07/22-134142', 100, 0.1, 3],\n",
              "       ['sigmoid', 42.66059923171997, 32, None, 0.0, '11/07/22-133302',\n",
              "        'Nadam', 'binary_crossentropy', 4, 51, 'elu', 32, 'long_funnel',\n",
              "        'HeNormal', '11/07/22-133345', 100, 0.01, 4],\n",
              "       ['sigmoid', 27.207896947860718, 32, None, 0.0, '11/07/22-133717',\n",
              "        'Nadam', 'binary_crossentropy', 2, 51, 'elu', 32, 'long_funnel',\n",
              "        'HeNormal', '11/07/22-133744', 100, 0.01, 5],\n",
              "       ['sigmoid', 26.394317865371704, 32, None, 0.0, '11/07/22-133603',\n",
              "        'Adam', 'binary_crossentropy', 4, 51, 'elu', 32, 'brick',\n",
              "        'HeNormal', '11/07/22-133629', 100, 0.1, 6],\n",
              "       ['sigmoid', 24.052563667297363, 32, None, 0.0, '11/07/22-133238',\n",
              "        'Adamax', 'logcosh', 2, 51, 'elu', 64, 'brick', 'HeNormal',\n",
              "        '11/07/22-133302', 100, 0.1, 7],\n",
              "       ['sigmoid', 27.923596143722534, 32, None, 0.5, '11/07/22-133919',\n",
              "        'Adam', 'logcosh', 4, 51, 'elu', 32, 'brick', 'GlorotNormal',\n",
              "        '11/07/22-133947', 100, 0.01, 8],\n",
              "       ['sigmoid', 24.992199897766113, 64, None, 0.5, '11/07/22-134428',\n",
              "        'Adamax', 'binary_crossentropy', 5, 51, 'relu', 64,\n",
              "        'long_funnel', 'HeNormal', '11/07/22-134452', 100, 0.1, 9]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get correlation for hyperparameters against a metric\n",
        "analyze_object.correlate('val_accuracy', ['accuracy', 'loss', 'val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMXJdx2JAWT3",
        "outputId": "206c5a59-aacc-428e-fed2-7cf3241d7e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "duration         0.006280\n",
              "round_epochs          NaN\n",
              "lr              -0.120802\n",
              "first_neuron     0.072316\n",
              "hidden_layers   -0.065774\n",
              "batch_size      -0.182635\n",
              "epochs                NaN\n",
              "dropout          0.116693\n",
              "Name: val_accuracy, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a regression plot for two dimensions \n",
        "analyze_object.plot_regs('val_accuracy', 'val_loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "X98d15ifAgMY",
        "outputId": "ceecbaf7-cd9a-4ed4-e128-c464dc68caac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a regression plot for two dimensions \n",
        "analyze_object.plot_regs('accuracy', 'loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "03wtr0uCBBlP",
        "outputId": "6dd7c745-bcd8-4505-f08a-d132afbffdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a regression plot for two dimensions \n",
        "analyze_object.plot_regs('loss', 'val_loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "_mPj-nfcCZqH",
        "outputId": "860b18a0-8e13-46bd-aaf2-5e4ba921c19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmap correlation\n",
        "analyze_object.plot_corr('val_loss', ['accuracy', 'loss', 'val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "zdObGb6dCkll",
        "outputId": "fa74873c-f4c6-42b8-9325-c8b73d97f8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a four dimensional bar grid\n",
        "analyze_object.plot_bars('batch_size', 'val_accuracy', 'first_neuron', 'lr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "EO76sAAXCu2Q",
        "outputId": "02ddc199-36be-4a3e-d084-f5a4f4824e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1250x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_object = ta.Evaluate(scan_object)\n",
        "evaluate_object.evaluate(X_train, Y_train, folds=10, metric='loss', task='continuous', asc = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzEW_OdaDBvr",
        "outputId": "97cbd37d-05d3-41fe-bc21-be5ee8a0b76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30272125035524367,\n",
              " 0.30606495797634126,\n",
              " 0.3010493965446949,\n",
              " 0.30272125035524367,\n",
              " 0.2868386391550303,\n",
              " 0.30606495797634126,\n",
              " 0.2860027122497559,\n",
              " 0.29937754273414613,\n",
              " 0.3127523732185364,\n",
              " 0.2910182736814022]"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_object.evaluate(X_test, Y_test, folds=10, metric='val_loss', task='continuous', asc = True, shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-nxdyaWFpX7",
        "outputId": "8f3610b6-859c-4f48-8f1c-adfa3101b522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35622057229280474,\n",
              " 0.3194397884607315,\n",
              " 0.32278349608182905,\n",
              " 0.292690127491951,\n",
              " 0.292690127491951,\n",
              " 0.3094086655974388,\n",
              " 0.32612720370292664,\n",
              " 0.3160960808396339,\n",
              " 0.29603383511304854,\n",
              " 0.2826590046286583]"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_object.evaluate(X_train, Y_train, folds=7, metric='accuracy', task='multi_class')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG55BurUFyBM",
        "outputId": "857ba2da-7abc-41f3-f87c-af7b8581bd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44156479217603917,\n",
              " 0.4426549536359199,\n",
              " 0.4421104054714216,\n",
              " 0.4499036608863199,\n",
              " 0.44670542635658916,\n",
              " 0.4423828125,\n",
              " 0.4453618261291889]"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_object.evaluate(X_test, Y_test, folds=7, metric='val_accuracy', task='multi_class')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TukgYQmWF91j",
        "outputId": "0a072224-ceb7-4114-92c4-d43672a976cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43339960238568587,\n",
              " 0.4265593561368209,\n",
              " 0.44874274661508706,\n",
              " 0.4265593561368209,\n",
              " 0.44874274661508706,\n",
              " 0.4411764705882353,\n",
              " 0.44660194174757284]"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ta.Deploy(scan_object=scan_object, model_name='churn_deploy2', metric='val_accuracy');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MEwckqCGZUn",
        "outputId": "5ad9c9e4-8c83-4457-9fac-7d2f349d9274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deploy package churn_deploy2 have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "churn = ta.Restore('churn_deploy2.zip')"
      ],
      "metadata": {
        "id": "w2KzSMvqGiE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions with the model\n",
        "predictions = churn.model.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN6EnzFiGpnM",
        "outputId": "2b54eac7-fbf6-4b0c-96f9-d24e2440514c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.55791146],\n",
              "       [0.32276145],\n",
              "       [0.21035355],\n",
              "       ...,\n",
              "       [0.3219514 ],\n",
              "       [0.75235254],\n",
              "       [0.18936513]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the meta-data for the experiment\n",
        "churn.details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "PyNdHb-RG80s",
        "outputId": "2ffc56b4-96b8-4f18-88bf-ebac1f1f3b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      0               1\n",
              "0                   NaN               0\n",
              "1       experiment_name           churn\n",
              "2         random_method         quantum\n",
              "3      reduction_method             NaN\n",
              "4    reduction_interval              50\n",
              "5      reduction_window              20\n",
              "6   reduction_threshold             0.2\n",
              "7      reduction_metric         val_acc\n",
              "8         experiment_id    110722132915\n",
              "9         complete_time  11/07/22/13:45\n",
              "10              x_shape      (8000, 13)\n",
              "11              y_shape         (8000,)"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beda7591-9d0e-4484-8ade-f37daa575e70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>experiment_name</td>\n",
              "      <td>churn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>random_method</td>\n",
              "      <td>quantum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>reduction_method</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>reduction_interval</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>reduction_window</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>reduction_threshold</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>reduction_metric</td>\n",
              "      <td>val_acc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>experiment_id</td>\n",
              "      <td>110722132915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>complete_time</td>\n",
              "      <td>11/07/22/13:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>x_shape</td>\n",
              "      <td>(8000, 13)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>y_shape</td>\n",
              "      <td>(8000,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beda7591-9d0e-4484-8ade-f37daa575e70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-beda7591-9d0e-4484-8ade-f37daa575e70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-beda7591-9d0e-4484-8ade-f37daa575e70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample of x data\n",
        "churn.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LwWCAR-2HMRH",
        "outputId": "cb308149-8a8c-47a3-e7b3-2cab67062d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5    6    7    8   \\\n",
              "0   1.836255 -0.183251 -0.350204 -1.225848  0.807737 -0.091202  1.0 -1.0  1.0   \n",
              "1  -0.450383  0.102810 -1.387538  0.577914 -0.911583 -1.395433  1.0  1.0  0.0   \n",
              "2  -0.988415 -0.755372  1.032908  1.112119 -0.911583  0.650366  1.0 -1.0  1.0   \n",
              "3  -0.740092  0.007457 -0.695982  1.442685  0.807737 -0.108761  1.0 -1.0  1.0   \n",
              "4   1.774174  1.056346  0.687130 -1.225848  0.807737 -1.565487  1.0  1.0  1.0   \n",
              "..       ...       ...       ...       ...       ...       ...  ...  ...  ...   \n",
              "95 -1.888585 -1.041433 -0.695982 -1.225848  0.807737  1.227155  1.0 -1.0  0.0   \n",
              "96  0.149730  0.293517 -1.041760  1.280337  0.807737  0.985690 -1.0  1.0  0.0   \n",
              "97  0.573948 -0.946079 -1.041760 -1.225848  0.807737 -1.423024  1.0  1.0  0.0   \n",
              "98  1.329263 -0.660018  1.724464  0.067991 -0.911583 -0.239681  1.0 -1.0  1.0   \n",
              "99  1.008513 -0.469311 -0.004426  0.120581 -0.911583  0.641843  1.0  1.0  1.0   \n",
              "\n",
              "     9    10   11   12  \n",
              "0   0.0  0.0  0.0  1.0  \n",
              "1   0.0  1.0  0.0  1.0  \n",
              "2   0.0  0.0  0.0  1.0  \n",
              "3   0.0  0.0  1.0  0.0  \n",
              "4   0.0  0.0  0.0  1.0  \n",
              "..  ...  ...  ...  ...  \n",
              "95  0.0  1.0  0.0  1.0  \n",
              "96  0.0  1.0  1.0  0.0  \n",
              "97  0.0  1.0  0.0  1.0  \n",
              "98  0.0  0.0  0.0  1.0  \n",
              "99  0.0  0.0  0.0  1.0  \n",
              "\n",
              "[100 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6982827f-d06c-4cbb-a44f-2a2927ed4526\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.836255</td>\n",
              "      <td>-0.183251</td>\n",
              "      <td>-0.350204</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>0.807737</td>\n",
              "      <td>-0.091202</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.450383</td>\n",
              "      <td>0.102810</td>\n",
              "      <td>-1.387538</td>\n",
              "      <td>0.577914</td>\n",
              "      <td>-0.911583</td>\n",
              "      <td>-1.395433</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.988415</td>\n",
              "      <td>-0.755372</td>\n",
              "      <td>1.032908</td>\n",
              "      <td>1.112119</td>\n",
              "      <td>-0.911583</td>\n",
              "      <td>0.650366</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.740092</td>\n",
              "      <td>0.007457</td>\n",
              "      <td>-0.695982</td>\n",
              "      <td>1.442685</td>\n",
              "      <td>0.807737</td>\n",
              "      <td>-0.108761</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.774174</td>\n",
              "      <td>1.056346</td>\n",
              "      <td>0.687130</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>0.807737</td>\n",
              "      <td>-1.565487</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>-1.888585</td>\n",
              "      <td>-1.041433</td>\n",
              "      <td>-0.695982</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>0.807737</td>\n",
              "      <td>1.227155</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.149730</td>\n",
              "      <td>0.293517</td>\n",
              "      <td>-1.041760</td>\n",
              "      <td>1.280337</td>\n",
              "      <td>0.807737</td>\n",
              "      <td>0.985690</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.573948</td>\n",
              "      <td>-0.946079</td>\n",
              "      <td>-1.041760</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>0.807737</td>\n",
              "      <td>-1.423024</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1.329263</td>\n",
              "      <td>-0.660018</td>\n",
              "      <td>1.724464</td>\n",
              "      <td>0.067991</td>\n",
              "      <td>-0.911583</td>\n",
              "      <td>-0.239681</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1.008513</td>\n",
              "      <td>-0.469311</td>\n",
              "      <td>-0.004426</td>\n",
              "      <td>0.120581</td>\n",
              "      <td>-0.911583</td>\n",
              "      <td>0.641843</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6982827f-d06c-4cbb-a44f-2a2927ed4526')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6982827f-d06c-4cbb-a44f-2a2927ed4526 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6982827f-d06c-4cbb-a44f-2a2927ed4526');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample of y data\n",
        "churn.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v52fEFOtHVwe",
        "outputId": "b6fa1ff0-f6ce-4b3c-b4cc-3908b5d42fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    0\n",
              "0   0\n",
              "1   0\n",
              "2   0\n",
              "3   0\n",
              "4   0\n",
              ".. ..\n",
              "95  0\n",
              "96  1\n",
              "97  0\n",
              "98  0\n",
              "99  0\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4e524af-18ec-4350-9625-a93ce2ed14e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4e524af-18ec-4350-9625-a93ce2ed14e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4e524af-18ec-4350-9625-a93ce2ed14e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4e524af-18ec-4350-9625-a93ce2ed14e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the results dataframe\n",
        "churn.results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qs-W4xT-Hbu-",
        "outputId": "f5e2f00a-0466-4eec-b4bc-6892f5e1c4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              start              end   duration  round_epochs      loss  \\\n",
              "0   11/07/22-132922  11/07/22-133005  42.852551            51  0.464736   \n",
              "1   11/07/22-133006  11/07/22-133030  24.258456            51  0.505315   \n",
              "2   11/07/22-133030  11/07/22-133058  27.890851            51  0.471682   \n",
              "3   11/07/22-133059  11/07/22-133126  27.440482            51  0.505352   \n",
              "4   11/07/22-133126  11/07/22-133209  42.646061            51  0.074764   \n",
              "5   11/07/22-133209  11/07/22-133237  27.782334            51  0.505402   \n",
              "6   11/07/22-133238  11/07/22-133302  24.052564            51  0.074719   \n",
              "7   11/07/22-133302  11/07/22-133345  42.660599            51  0.465356   \n",
              "8   11/07/22-133345  11/07/22-133413  27.923140            51  0.505603   \n",
              "9   11/07/22-133413  11/07/22-133455  41.843487            51  0.074689   \n",
              "10  11/07/22-133455  11/07/22-133520  24.343301            51  0.074750   \n",
              "11  11/07/22-133520  11/07/22-133603  42.758983            51  0.505365   \n",
              "12  11/07/22-133603  11/07/22-133629  26.394318            51  0.469266   \n",
              "13  11/07/22-133630  11/07/22-133653  23.912782            51  0.505799   \n",
              "14  11/07/22-133654  11/07/22-133717  22.959528            51  0.074702   \n",
              "15  11/07/22-133717  11/07/22-133744  27.207897            51  0.466995   \n",
              "16  11/07/22-133744  11/07/22-133807  22.965834            51  0.074709   \n",
              "17  11/07/22-133808  11/07/22-133850  41.992130            51  0.074727   \n",
              "18  11/07/22-133850  11/07/22-133919  28.450734            51  0.427834   \n",
              "19  11/07/22-133919  11/07/22-133947  27.923596            51  0.074712   \n",
              "20  11/07/22-133947  11/07/22-134029  41.869665            51  0.074748   \n",
              "21  11/07/22-134029  11/07/22-134112  42.716996            51  0.074711   \n",
              "22  11/07/22-134112  11/07/22-134142  29.324832            51  0.466648   \n",
              "23  11/07/22-134142  11/07/22-134207  24.592016            51  0.505467   \n",
              "24  11/07/22-134207  11/07/22-134249  41.814621            51  0.074733   \n",
              "25  11/07/22-134249  11/07/22-134331  41.877449            51  0.074762   \n",
              "26  11/07/22-134331  11/07/22-134401  30.066855            51  0.074707   \n",
              "27  11/07/22-134402  11/07/22-134427  25.570290            51  0.505127   \n",
              "28  11/07/22-134428  11/07/22-134452  24.992200            51  0.505169   \n",
              "29  11/07/22-134453  11/07/22-134535  41.952977            51  0.505557   \n",
              "\n",
              "    accuracy  val_loss  val_accuracy    lr  first_neuron  ...  batch_size  \\\n",
              "0   0.808500  0.436373        0.8325  0.10            64  ...          32   \n",
              "1   0.796667  0.487601        0.8095  0.01            32  ...          64   \n",
              "2   0.804000  0.448358        0.8300  0.01            32  ...          32   \n",
              "3   0.796667  0.488024        0.8095  0.10            32  ...          32   \n",
              "4   0.796667  0.070856        0.8095  0.10            64  ...          32   \n",
              "5   0.796667  0.487853        0.8095  0.10            64  ...          32   \n",
              "6   0.796667  0.070888        0.8095  0.10            64  ...          32   \n",
              "7   0.804500  0.462804        0.8190  0.01            32  ...          32   \n",
              "8   0.796667  0.488069        0.8095  0.10            32  ...          32   \n",
              "9   0.796667  0.070853        0.8095  0.10            64  ...          32   \n",
              "10  0.796667  0.070869        0.8095  0.01            32  ...          32   \n",
              "11  0.796667  0.487394        0.8095  0.10            64  ...          32   \n",
              "12  0.803833  0.448865        0.8165  0.10            32  ...          32   \n",
              "13  0.796667  0.487087        0.8095  0.10            64  ...          64   \n",
              "14  0.796667  0.070950        0.8095  0.01            32  ...          32   \n",
              "15  0.805000  0.434180        0.8190  0.01            32  ...          32   \n",
              "16  0.796667  0.071087        0.8095  0.01            32  ...          64   \n",
              "17  0.796667  0.070858        0.8095  0.10            32  ...          64   \n",
              "18  0.854333  0.459182        0.8400  0.01            64  ...          32   \n",
              "19  0.796667  0.070884        0.8095  0.01            32  ...          32   \n",
              "20  0.796667  0.070909        0.8095  0.01            64  ...          64   \n",
              "21  0.796667  0.070867        0.8095  0.01            64  ...          64   \n",
              "22  0.802667  0.431633        0.8280  0.10            64  ...          64   \n",
              "23  0.796667  0.487714        0.8095  0.01            32  ...          32   \n",
              "24  0.796667  0.070923        0.8095  0.10            64  ...          32   \n",
              "25  0.796667  0.070880        0.8095  0.01            64  ...          32   \n",
              "26  0.796667  0.071486        0.8095  0.01            64  ...          32   \n",
              "27  0.796667  0.487221        0.8095  0.10            32  ...          64   \n",
              "28  0.796667  0.489250        0.8095  0.10            64  ...          64   \n",
              "29  0.796667  0.486966        0.8095  0.10            64  ...          64   \n",
              "\n",
              "    epochs  dropout  weight_regulizer emb_output_dims        shape optimizer  \\\n",
              "0      100      0.0      GlorotNormal             NaN  long_funnel     Nadam   \n",
              "1      100      0.0          HeNormal             NaN        brick    Adamax   \n",
              "2      100      0.5          HeNormal             NaN        brick      Adam   \n",
              "3      100      0.0      GlorotNormal             NaN        brick      Adam   \n",
              "4      100      0.5          HeNormal             NaN        brick     Nadam   \n",
              "5      100      0.5      GlorotNormal             NaN        brick     Nadam   \n",
              "6      100      0.0          HeNormal             NaN        brick    Adamax   \n",
              "7      100      0.0          HeNormal             NaN  long_funnel     Nadam   \n",
              "8      100      0.5      GlorotNormal             NaN        brick     Nadam   \n",
              "9      100      0.0      GlorotNormal             NaN        brick    Adamax   \n",
              "10     100      0.5      GlorotNormal             NaN  long_funnel    Adamax   \n",
              "11     100      0.0      GlorotNormal             NaN        brick     Nadam   \n",
              "12     100      0.0          HeNormal             NaN        brick      Adam   \n",
              "13     100      0.0          HeNormal             NaN  long_funnel    Adamax   \n",
              "14     100      0.0          HeNormal             NaN  long_funnel    Adamax   \n",
              "15     100      0.0          HeNormal             NaN  long_funnel     Nadam   \n",
              "16     100      0.0          HeNormal             NaN  long_funnel    Adamax   \n",
              "17     100      0.0          HeNormal             NaN  long_funnel    Adamax   \n",
              "18     100      0.5          HeNormal             NaN  long_funnel      Adam   \n",
              "19     100      0.5      GlorotNormal             NaN        brick      Adam   \n",
              "20     100      0.0      GlorotNormal             NaN        brick      Adam   \n",
              "21     100      0.5          HeNormal             NaN  long_funnel     Nadam   \n",
              "22     100      0.5      GlorotNormal             NaN        brick     Nadam   \n",
              "23     100      0.5          HeNormal             NaN  long_funnel    Adamax   \n",
              "24     100      0.5          HeNormal             NaN  long_funnel      Adam   \n",
              "25     100      0.0          HeNormal             NaN        brick      Adam   \n",
              "26     100      0.5          HeNormal             NaN  long_funnel     Nadam   \n",
              "27     100      0.5      GlorotNormal             NaN        brick    Adamax   \n",
              "28     100      0.5          HeNormal             NaN  long_funnel    Adamax   \n",
              "29     100      0.0      GlorotNormal             NaN  long_funnel    Adamax   \n",
              "\n",
              "                 losses activation last_activation  \n",
              "0   binary_crossentropy        elu         sigmoid  \n",
              "1   binary_crossentropy       relu         sigmoid  \n",
              "2   binary_crossentropy        elu         sigmoid  \n",
              "3   binary_crossentropy       relu         sigmoid  \n",
              "4               logcosh        elu         sigmoid  \n",
              "5   binary_crossentropy       relu         sigmoid  \n",
              "6               logcosh        elu         sigmoid  \n",
              "7   binary_crossentropy        elu         sigmoid  \n",
              "8   binary_crossentropy       relu         sigmoid  \n",
              "9               logcosh        elu         sigmoid  \n",
              "10              logcosh        elu         sigmoid  \n",
              "11  binary_crossentropy       relu         sigmoid  \n",
              "12  binary_crossentropy        elu         sigmoid  \n",
              "13  binary_crossentropy        elu         sigmoid  \n",
              "14              logcosh       relu         sigmoid  \n",
              "15  binary_crossentropy        elu         sigmoid  \n",
              "16              logcosh        elu         sigmoid  \n",
              "17              logcosh        elu         sigmoid  \n",
              "18  binary_crossentropy       relu         sigmoid  \n",
              "19              logcosh        elu         sigmoid  \n",
              "20              logcosh        elu         sigmoid  \n",
              "21              logcosh       relu         sigmoid  \n",
              "22  binary_crossentropy        elu         sigmoid  \n",
              "23  binary_crossentropy        elu         sigmoid  \n",
              "24              logcosh       relu         sigmoid  \n",
              "25              logcosh       relu         sigmoid  \n",
              "26              logcosh        elu         sigmoid  \n",
              "27  binary_crossentropy        elu         sigmoid  \n",
              "28  binary_crossentropy       relu         sigmoid  \n",
              "29  binary_crossentropy        elu         sigmoid  \n",
              "\n",
              "[30 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a938d821-a8da-46dd-87bc-9ad8971a1a5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>lr</th>\n",
              "      <th>first_neuron</th>\n",
              "      <th>...</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>dropout</th>\n",
              "      <th>weight_regulizer</th>\n",
              "      <th>emb_output_dims</th>\n",
              "      <th>shape</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>losses</th>\n",
              "      <th>activation</th>\n",
              "      <th>last_activation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/07/22-132922</td>\n",
              "      <td>11/07/22-133005</td>\n",
              "      <td>42.852551</td>\n",
              "      <td>51</td>\n",
              "      <td>0.464736</td>\n",
              "      <td>0.808500</td>\n",
              "      <td>0.436373</td>\n",
              "      <td>0.8325</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11/07/22-133006</td>\n",
              "      <td>11/07/22-133030</td>\n",
              "      <td>24.258456</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505315</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487601</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11/07/22-133030</td>\n",
              "      <td>11/07/22-133058</td>\n",
              "      <td>27.890851</td>\n",
              "      <td>51</td>\n",
              "      <td>0.471682</td>\n",
              "      <td>0.804000</td>\n",
              "      <td>0.448358</td>\n",
              "      <td>0.8300</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/07/22-133059</td>\n",
              "      <td>11/07/22-133126</td>\n",
              "      <td>27.440482</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505352</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.488024</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11/07/22-133126</td>\n",
              "      <td>11/07/22-133209</td>\n",
              "      <td>42.646061</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074764</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070856</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11/07/22-133209</td>\n",
              "      <td>11/07/22-133237</td>\n",
              "      <td>27.782334</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505402</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487853</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11/07/22-133238</td>\n",
              "      <td>11/07/22-133302</td>\n",
              "      <td>24.052564</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074719</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070888</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11/07/22-133302</td>\n",
              "      <td>11/07/22-133345</td>\n",
              "      <td>42.660599</td>\n",
              "      <td>51</td>\n",
              "      <td>0.465356</td>\n",
              "      <td>0.804500</td>\n",
              "      <td>0.462804</td>\n",
              "      <td>0.8190</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11/07/22-133345</td>\n",
              "      <td>11/07/22-133413</td>\n",
              "      <td>27.923140</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505603</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.488069</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11/07/22-133413</td>\n",
              "      <td>11/07/22-133455</td>\n",
              "      <td>41.843487</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074689</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070853</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11/07/22-133455</td>\n",
              "      <td>11/07/22-133520</td>\n",
              "      <td>24.343301</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074750</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070869</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11/07/22-133520</td>\n",
              "      <td>11/07/22-133603</td>\n",
              "      <td>42.758983</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505365</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487394</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11/07/22-133603</td>\n",
              "      <td>11/07/22-133629</td>\n",
              "      <td>26.394318</td>\n",
              "      <td>51</td>\n",
              "      <td>0.469266</td>\n",
              "      <td>0.803833</td>\n",
              "      <td>0.448865</td>\n",
              "      <td>0.8165</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11/07/22-133630</td>\n",
              "      <td>11/07/22-133653</td>\n",
              "      <td>23.912782</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505799</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487087</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11/07/22-133654</td>\n",
              "      <td>11/07/22-133717</td>\n",
              "      <td>22.959528</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074702</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070950</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11/07/22-133717</td>\n",
              "      <td>11/07/22-133744</td>\n",
              "      <td>27.207897</td>\n",
              "      <td>51</td>\n",
              "      <td>0.466995</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.434180</td>\n",
              "      <td>0.8190</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11/07/22-133744</td>\n",
              "      <td>11/07/22-133807</td>\n",
              "      <td>22.965834</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074709</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.071087</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11/07/22-133808</td>\n",
              "      <td>11/07/22-133850</td>\n",
              "      <td>41.992130</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074727</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070858</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11/07/22-133850</td>\n",
              "      <td>11/07/22-133919</td>\n",
              "      <td>28.450734</td>\n",
              "      <td>51</td>\n",
              "      <td>0.427834</td>\n",
              "      <td>0.854333</td>\n",
              "      <td>0.459182</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>11/07/22-133919</td>\n",
              "      <td>11/07/22-133947</td>\n",
              "      <td>27.923596</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074712</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070884</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>11/07/22-133947</td>\n",
              "      <td>11/07/22-134029</td>\n",
              "      <td>41.869665</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074748</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070909</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>11/07/22-134029</td>\n",
              "      <td>11/07/22-134112</td>\n",
              "      <td>42.716996</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074711</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070867</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>11/07/22-134112</td>\n",
              "      <td>11/07/22-134142</td>\n",
              "      <td>29.324832</td>\n",
              "      <td>51</td>\n",
              "      <td>0.466648</td>\n",
              "      <td>0.802667</td>\n",
              "      <td>0.431633</td>\n",
              "      <td>0.8280</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>11/07/22-134142</td>\n",
              "      <td>11/07/22-134207</td>\n",
              "      <td>24.592016</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505467</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487714</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11/07/22-134207</td>\n",
              "      <td>11/07/22-134249</td>\n",
              "      <td>41.814621</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074733</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070923</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>11/07/22-134249</td>\n",
              "      <td>11/07/22-134331</td>\n",
              "      <td>41.877449</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074762</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.070880</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>11/07/22-134331</td>\n",
              "      <td>11/07/22-134401</td>\n",
              "      <td>30.066855</td>\n",
              "      <td>51</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.071486</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>logcosh</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>11/07/22-134402</td>\n",
              "      <td>11/07/22-134427</td>\n",
              "      <td>25.570290</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505127</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.487221</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>brick</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>11/07/22-134428</td>\n",
              "      <td>11/07/22-134452</td>\n",
              "      <td>24.992200</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505169</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.489250</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>HeNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>relu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>11/07/22-134453</td>\n",
              "      <td>11/07/22-134535</td>\n",
              "      <td>41.952977</td>\n",
              "      <td>51</td>\n",
              "      <td>0.505557</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.486966</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.10</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GlorotNormal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>long_funnel</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>binary_crossentropy</td>\n",
              "      <td>elu</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows  21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a938d821-a8da-46dd-87bc-9ad8971a1a5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a938d821-a8da-46dd-87bc-9ad8971a1a5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a938d821-a8da-46dd-87bc-9ad8971a1a5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "mse(Y_test, predictions).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9d92N6VIRlb",
        "outputId": "f97dd31f-8b2e-4f5a-ae6c-fdd13470b96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24251989"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using 'none' reduction type.\n",
        "mse1 = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "mse1(Y_test, predictions).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPe7BY13JAfH",
        "outputId": "2c112d91-2208-4a40-e309-6f243c483a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.28601575, 0.18145093, 0.17053448, ..., 0.1812819 , 0.45600855,\n",
              "       0.17129593], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***First Model After Optimization***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gcfppzreNny-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after using keras and talos, uninstall the old version that is independent from tensorflow then you can use the learning rate with the optimizer (overlapping version's problem)\n",
        "pip uninstall keras"
      ],
      "metadata": {
        "id": "Wvu_m4C13XrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining/creating a sequential model and initilazing the weights using He normal initialization and using elu as an activation function\n",
        "#and with Batch Normalization with Momentum defaults to 0.95\n",
        "#The hyperparameter  defaults to 0.005,\n",
        "#The hyperparameter  defaults to an all-zeros vector\n",
        "#The hyperparameter  defaults to an all-ones vector\n",
        "#compile the model using the optimizer Nadam and the logcosh as loss function\n",
        "#fit the model with the mini-batch Gradient Descent using 32 batches and 51 epochs\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, kernel_initializer='HeNormal', kernel_regularizer=regularizers.l2(0.09), input_shape=(n_features,), activation='elu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(77, kernel_initializer='HeNormal', kernel_regularizer=regularizers.l2(0.08), activation='elu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(70, kernel_initializer='HeNormal', kernel_regularizer=regularizers.l2(0.07), activation='elu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(70,  kernel_initializer='HeNormal', kernel_regularizer=regularizers.l2(0.06), activation='elu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(63, kernel_initializer='HeNormal', activation='elu'))\n",
        "BatchNormalization(\n",
        "              momentum=0.95, \n",
        "              epsilon=0.005,\n",
        "              center = True,\n",
        "              scale = True,\n",
        "              beta_initializer='zeros', \n",
        "              gamma_initializer='ones',\n",
        "              moving_mean_initializer='zeros',\n",
        "            moving_variance_initializer='ones',\n",
        "            beta_regularizer=None,\n",
        "            gamma_regularizer=None,\n",
        "            beta_constraint=None,\n",
        "            gamma_constraint=None,\n",
        "            ),\n",
        "model.add(Dense(1, activation='sigmoid', name=\"predictions\"))"
      ],
      "metadata": {
        "id": "B-Dt-2yxZn4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4zLPLDPju70",
        "outputId": "e9b48a1f-01f6-4f44-9bdf-3a2ae0fac24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 77)                5005      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 70)                5460      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 70)                4970      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 63)                4473      \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1)                 64        \n",
            "=================================================================\n",
            "Total params: 20,868\n",
            "Trainable params: 20,868\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model using the optimizer Nadam with learning rate equal 0.01 and the logcosh as loss function\n",
        "opt = Nadam(learning_rate=0.01)\n",
        "model.compile(optimizer = opt, loss='logcosh', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1UVqv6WJjxoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We call model.fit() to fit our model to the training data:\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    epochs=51, \n",
        "    validation_split=0.25,\n",
        "    batch_size=32, \n",
        "    verbose=2,\n",
        "    validation_data=(X_test, Y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mD37FQ7jdBl",
        "outputId": "1607c421-3c02-4cb6-a039-5d2d6bba1f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 3s - loss: 0.0905 - accuracy: 0.7998 - val_loss: 0.0928 - val_accuracy: 0.7970\n",
            "Epoch 2/51\n",
            "188/188 - 1s - loss: 0.0903 - accuracy: 0.7998 - val_loss: 0.0910 - val_accuracy: 0.7970\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.0899 - accuracy: 0.7998 - val_loss: 0.0912 - val_accuracy: 0.7970\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.0899 - accuracy: 0.7998 - val_loss: 0.0906 - val_accuracy: 0.7970\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.0894 - accuracy: 0.7998 - val_loss: 0.0904 - val_accuracy: 0.7970\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.0894 - accuracy: 0.7998 - val_loss: 0.0906 - val_accuracy: 0.7970\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.0893 - accuracy: 0.7998 - val_loss: 0.0906 - val_accuracy: 0.7970\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0891 - accuracy: 0.7998 - val_loss: 0.0901 - val_accuracy: 0.7970\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0890 - accuracy: 0.7998 - val_loss: 0.0903 - val_accuracy: 0.7970\n",
            "Epoch 10/51\n",
            "188/188 - 1s - loss: 0.0889 - accuracy: 0.7998 - val_loss: 0.0902 - val_accuracy: 0.7970\n",
            "Epoch 11/51\n",
            "188/188 - 1s - loss: 0.0888 - accuracy: 0.7998 - val_loss: 0.0901 - val_accuracy: 0.7970\n",
            "Epoch 12/51\n",
            "188/188 - 1s - loss: 0.0887 - accuracy: 0.7998 - val_loss: 0.0898 - val_accuracy: 0.7970\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0886 - accuracy: 0.7998 - val_loss: 0.0896 - val_accuracy: 0.7970\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0885 - accuracy: 0.7998 - val_loss: 0.0897 - val_accuracy: 0.7970\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0885 - accuracy: 0.7998 - val_loss: 0.0899 - val_accuracy: 0.7970\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0885 - accuracy: 0.7998 - val_loss: 0.0898 - val_accuracy: 0.7970\n",
            "Epoch 17/51\n",
            "188/188 - 1s - loss: 0.0884 - accuracy: 0.7998 - val_loss: 0.0894 - val_accuracy: 0.7970\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0883 - accuracy: 0.7998 - val_loss: 0.0894 - val_accuracy: 0.7970\n",
            "Epoch 19/51\n",
            "188/188 - 1s - loss: 0.0882 - accuracy: 0.7998 - val_loss: 0.0895 - val_accuracy: 0.7970\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0882 - accuracy: 0.7998 - val_loss: 0.0896 - val_accuracy: 0.7970\n",
            "Epoch 21/51\n",
            "188/188 - 1s - loss: 0.0882 - accuracy: 0.7998 - val_loss: 0.0893 - val_accuracy: 0.7970\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0881 - accuracy: 0.7998 - val_loss: 0.0892 - val_accuracy: 0.7970\n",
            "Epoch 23/51\n",
            "188/188 - 1s - loss: 0.0881 - accuracy: 0.7998 - val_loss: 0.0892 - val_accuracy: 0.7970\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0880 - accuracy: 0.7998 - val_loss: 0.0893 - val_accuracy: 0.7970\n",
            "Epoch 25/51\n",
            "188/188 - 1s - loss: 0.0880 - accuracy: 0.7998 - val_loss: 0.0892 - val_accuracy: 0.7970\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0879 - accuracy: 0.7998 - val_loss: 0.0891 - val_accuracy: 0.7970\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0879 - accuracy: 0.7998 - val_loss: 0.0891 - val_accuracy: 0.7970\n",
            "Epoch 28/51\n",
            "188/188 - 1s - loss: 0.0879 - accuracy: 0.7998 - val_loss: 0.0891 - val_accuracy: 0.7970\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.0879 - accuracy: 0.7998 - val_loss: 0.0890 - val_accuracy: 0.7970\n",
            "Epoch 30/51\n",
            "188/188 - 1s - loss: 0.0878 - accuracy: 0.7998 - val_loss: 0.0890 - val_accuracy: 0.7970\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.0878 - accuracy: 0.7998 - val_loss: 0.0890 - val_accuracy: 0.7970\n",
            "Epoch 32/51\n",
            "188/188 - 1s - loss: 0.0878 - accuracy: 0.7998 - val_loss: 0.0890 - val_accuracy: 0.7970\n",
            "Epoch 33/51\n",
            "188/188 - 1s - loss: 0.0877 - accuracy: 0.7998 - val_loss: 0.0889 - val_accuracy: 0.7970\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0877 - accuracy: 0.7998 - val_loss: 0.0889 - val_accuracy: 0.7970\n",
            "Epoch 35/51\n",
            "188/188 - 1s - loss: 0.0877 - accuracy: 0.7998 - val_loss: 0.0889 - val_accuracy: 0.7970\n",
            "Epoch 36/51\n",
            "188/188 - 1s - loss: 0.0877 - accuracy: 0.7998 - val_loss: 0.0889 - val_accuracy: 0.7970\n",
            "Epoch 37/51\n",
            "188/188 - 1s - loss: 0.0876 - accuracy: 0.7998 - val_loss: 0.0888 - val_accuracy: 0.7970\n",
            "Epoch 38/51\n",
            "188/188 - 1s - loss: 0.0876 - accuracy: 0.7998 - val_loss: 0.0888 - val_accuracy: 0.7970\n",
            "Epoch 39/51\n",
            "188/188 - 1s - loss: 0.0876 - accuracy: 0.7998 - val_loss: 0.0888 - val_accuracy: 0.7970\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0876 - accuracy: 0.7998 - val_loss: 0.0888 - val_accuracy: 0.7970\n",
            "Epoch 41/51\n",
            "188/188 - 0s - loss: 0.0876 - accuracy: 0.7998 - val_loss: 0.0888 - val_accuracy: 0.7970\n",
            "Epoch 42/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0887 - val_accuracy: 0.7970\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0887 - val_accuracy: 0.7970\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0887 - val_accuracy: 0.7970\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0887 - val_accuracy: 0.7970\n",
            "Epoch 46/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0887 - val_accuracy: 0.7970\n",
            "Epoch 47/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0887 - val_accuracy: 0.7970\n",
            "Epoch 48/51\n",
            "188/188 - 1s - loss: 0.0875 - accuracy: 0.7998 - val_loss: 0.0886 - val_accuracy: 0.7970\n",
            "Epoch 49/51\n",
            "188/188 - 1s - loss: 0.0874 - accuracy: 0.7998 - val_loss: 0.0886 - val_accuracy: 0.7970\n",
            "Epoch 50/51\n",
            "188/188 - 1s - loss: 0.0874 - accuracy: 0.7998 - val_loss: 0.0886 - val_accuracy: 0.7970\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0874 - accuracy: 0.7998 - val_loss: 0.0886 - val_accuracy: 0.7970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model in training model:\n",
        "loss, acc = model.evaluate(X_train, Y_train, batch_size=128, verbose=2)\n",
        "print('Train Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "ziUn0mp0OEQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1858d950-a1e0-48b7-fabe-65ab73f5f0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 - 0s - loss: 0.0740 - accuracy: 0.7999\n",
            "Train Accuracy: 0.800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To evaluate the model on the test set:\n",
        "loss, acc = model.evaluate(X_test, Y_test, batch_size=128, verbose=2)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vHWWebDFntX",
        "outputId": "df4fdcbc-e334-434c-d9e8-c64d2cfdd675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 - 0s - loss: 0.0789 - accuracy: 0.7820\n",
            "Test Accuracy: 0.782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting training and validation accuracy to observe how the accuracy of our model improves over time:\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()\n",
        "  \n",
        "plot_metric(history, 'accuracy')"
      ],
      "metadata": {
        "id": "ezvTPLSuJxDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b05266b0-ffcf-4d14-9c68-f6565fef77a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#By running plot_metric(history, 'loss') to plot the progress on loss:\n",
        "plot_metric(history, 'loss')"
      ],
      "metadata": {
        "id": "M4ToYRmHLjuT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "18e008b1-3edf-4f30-a206-4f6be4f0340a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Second Model After Optimization***"
      ],
      "metadata": {
        "id": "jurq4sEr67ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining/creating a sequential model and initilazing the weights using Glorot Normal (Xavier) initialization and using relu as an activation function\n",
        "#and with Batch Normalization with Momentum defaults to 0.95\n",
        "#The hyperparameter  defaults to 0.005,\n",
        "#The hyperparameter  defaults to an all-zeros vector\n",
        "#The hyperparameter  defaults to an all-ones vector\n",
        "#compile the model using the optimizer Adam with learning rate equal 0.1 and the logcosh as loss function\n",
        "#fit the model with the mini-batch Gradient Descent using 32 batches and 51 epochs\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, kernel_initializer='GlorotNormal', kernel_regularizer=regularizers.l2(0.1), input_shape=(n_features,), activation='relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(77, kernel_initializer='GlorotNormal', kernel_regularizer=regularizers.l2(0.08), activation='relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(70, kernel_initializer='GlorotNormal', kernel_regularizer=regularizers.l2(0.08), activation='relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(70,  kernel_initializer='GlorotNormal', kernel_regularizer=regularizers.l2(0.1), activation='relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(63, kernel_initializer='GlorotNormal', activation='relu'))\n",
        "BatchNormalization(\n",
        "              momentum=0.95, \n",
        "              epsilon=0.005,\n",
        "              center = True,\n",
        "              scale = True,\n",
        "              beta_initializer='zeros', \n",
        "              gamma_initializer='ones',\n",
        "              moving_mean_initializer='zeros',\n",
        "            moving_variance_initializer='ones',\n",
        "            beta_regularizer=None,\n",
        "            gamma_regularizer=None,\n",
        "            beta_constraint=None,\n",
        "            gamma_constraint=None,\n",
        "            ),\n",
        "model.add(Dense(1, activation='sigmoid', name=\"predictions\"))\n",
        "\n",
        "#compile the model using the optimizer Nadam and the categorical crossentropy as loss\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer = opt, loss='logcosh', metrics=['accuracy'])\n",
        "\n",
        "#We call model.fit() to fit our model to the training data:\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    epochs=51, \n",
        "    validation_split=0.25,\n",
        "    batch_size=32, \n",
        "    verbose=2,\n",
        "    validation_data=(X_test, Y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx0GzULSDgtT",
        "outputId": "f046653c-e5b9-47ae-ca26-0d43357f0c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "188/188 - 1s - loss: 0.4679 - accuracy: 0.7967 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 2/51\n",
            "188/188 - 0s - loss: 0.0744 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 3/51\n",
            "188/188 - 1s - loss: 0.0744 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 4/51\n",
            "188/188 - 1s - loss: 0.0744 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 5/51\n",
            "188/188 - 1s - loss: 0.0744 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 6/51\n",
            "188/188 - 1s - loss: 0.0744 - accuracy: 0.7982 - val_loss: 0.0724 - val_accuracy: 0.8050\n",
            "Epoch 7/51\n",
            "188/188 - 1s - loss: 0.0751 - accuracy: 0.7982 - val_loss: 0.0763 - val_accuracy: 0.8050\n",
            "Epoch 8/51\n",
            "188/188 - 1s - loss: 0.0840 - accuracy: 0.7982 - val_loss: 0.0795 - val_accuracy: 0.8050\n",
            "Epoch 9/51\n",
            "188/188 - 1s - loss: 0.0815 - accuracy: 0.7982 - val_loss: 0.0801 - val_accuracy: 0.8050\n",
            "Epoch 10/51\n",
            "188/188 - 0s - loss: 0.0820 - accuracy: 0.7982 - val_loss: 0.0788 - val_accuracy: 0.8050\n",
            "Epoch 11/51\n",
            "188/188 - 0s - loss: 0.0811 - accuracy: 0.7982 - val_loss: 0.0789 - val_accuracy: 0.8050\n",
            "Epoch 12/51\n",
            "188/188 - 0s - loss: 0.0788 - accuracy: 0.7982 - val_loss: 0.0804 - val_accuracy: 0.8050\n",
            "Epoch 13/51\n",
            "188/188 - 1s - loss: 0.0818 - accuracy: 0.7982 - val_loss: 0.0793 - val_accuracy: 0.8050\n",
            "Epoch 14/51\n",
            "188/188 - 1s - loss: 0.0801 - accuracy: 0.7982 - val_loss: 0.0784 - val_accuracy: 0.8050\n",
            "Epoch 15/51\n",
            "188/188 - 1s - loss: 0.0808 - accuracy: 0.7982 - val_loss: 0.0791 - val_accuracy: 0.8050\n",
            "Epoch 16/51\n",
            "188/188 - 1s - loss: 0.0811 - accuracy: 0.7982 - val_loss: 0.0812 - val_accuracy: 0.8050\n",
            "Epoch 17/51\n",
            "188/188 - 0s - loss: 0.0835 - accuracy: 0.7982 - val_loss: 0.0799 - val_accuracy: 0.8050\n",
            "Epoch 18/51\n",
            "188/188 - 1s - loss: 0.0799 - accuracy: 0.7982 - val_loss: 0.0773 - val_accuracy: 0.8050\n",
            "Epoch 19/51\n",
            "188/188 - 0s - loss: 0.0799 - accuracy: 0.7982 - val_loss: 0.0784 - val_accuracy: 0.8050\n",
            "Epoch 20/51\n",
            "188/188 - 1s - loss: 0.0829 - accuracy: 0.7982 - val_loss: 0.0805 - val_accuracy: 0.8050\n",
            "Epoch 21/51\n",
            "188/188 - 0s - loss: 0.0821 - accuracy: 0.7982 - val_loss: 0.0796 - val_accuracy: 0.8050\n",
            "Epoch 22/51\n",
            "188/188 - 1s - loss: 0.0796 - accuracy: 0.7982 - val_loss: 0.0762 - val_accuracy: 0.8050\n",
            "Epoch 23/51\n",
            "188/188 - 0s - loss: 0.0807 - accuracy: 0.7982 - val_loss: 0.0804 - val_accuracy: 0.8050\n",
            "Epoch 24/51\n",
            "188/188 - 1s - loss: 0.0823 - accuracy: 0.7982 - val_loss: 0.0803 - val_accuracy: 0.8050\n",
            "Epoch 25/51\n",
            "188/188 - 0s - loss: 0.0807 - accuracy: 0.7982 - val_loss: 0.0777 - val_accuracy: 0.8050\n",
            "Epoch 26/51\n",
            "188/188 - 1s - loss: 0.0810 - accuracy: 0.7982 - val_loss: 0.0800 - val_accuracy: 0.8050\n",
            "Epoch 27/51\n",
            "188/188 - 1s - loss: 0.0829 - accuracy: 0.7982 - val_loss: 0.0791 - val_accuracy: 0.8050\n",
            "Epoch 28/51\n",
            "188/188 - 0s - loss: 0.0808 - accuracy: 0.7982 - val_loss: 0.0782 - val_accuracy: 0.8050\n",
            "Epoch 29/51\n",
            "188/188 - 1s - loss: 0.0810 - accuracy: 0.7982 - val_loss: 0.0803 - val_accuracy: 0.8050\n",
            "Epoch 30/51\n",
            "188/188 - 0s - loss: 0.0811 - accuracy: 0.7982 - val_loss: 0.0785 - val_accuracy: 0.8050\n",
            "Epoch 31/51\n",
            "188/188 - 1s - loss: 0.0806 - accuracy: 0.7982 - val_loss: 0.0780 - val_accuracy: 0.8050\n",
            "Epoch 32/51\n",
            "188/188 - 0s - loss: 0.0810 - accuracy: 0.7982 - val_loss: 0.0793 - val_accuracy: 0.8050\n",
            "Epoch 33/51\n",
            "188/188 - 0s - loss: 0.0807 - accuracy: 0.7982 - val_loss: 0.0785 - val_accuracy: 0.8050\n",
            "Epoch 34/51\n",
            "188/188 - 1s - loss: 0.0806 - accuracy: 0.7982 - val_loss: 0.0792 - val_accuracy: 0.8050\n",
            "Epoch 35/51\n",
            "188/188 - 0s - loss: 0.0808 - accuracy: 0.7982 - val_loss: 0.0787 - val_accuracy: 0.8050\n",
            "Epoch 36/51\n",
            "188/188 - 0s - loss: 0.0805 - accuracy: 0.7982 - val_loss: 0.0781 - val_accuracy: 0.8050\n",
            "Epoch 37/51\n",
            "188/188 - 0s - loss: 0.0805 - accuracy: 0.7982 - val_loss: 0.0787 - val_accuracy: 0.8050\n",
            "Epoch 38/51\n",
            "188/188 - 0s - loss: 0.0806 - accuracy: 0.7982 - val_loss: 0.0785 - val_accuracy: 0.8050\n",
            "Epoch 39/51\n",
            "188/188 - 0s - loss: 0.0804 - accuracy: 0.7982 - val_loss: 0.0783 - val_accuracy: 0.8050\n",
            "Epoch 40/51\n",
            "188/188 - 0s - loss: 0.0808 - accuracy: 0.7982 - val_loss: 0.0780 - val_accuracy: 0.8050\n",
            "Epoch 41/51\n",
            "188/188 - 1s - loss: 0.0806 - accuracy: 0.7982 - val_loss: 0.0778 - val_accuracy: 0.8050\n",
            "Epoch 42/51\n",
            "188/188 - 0s - loss: 0.0804 - accuracy: 0.7982 - val_loss: 0.0792 - val_accuracy: 0.8050\n",
            "Epoch 43/51\n",
            "188/188 - 1s - loss: 0.0807 - accuracy: 0.7982 - val_loss: 0.0787 - val_accuracy: 0.8050\n",
            "Epoch 44/51\n",
            "188/188 - 1s - loss: 0.0805 - accuracy: 0.7982 - val_loss: 0.0782 - val_accuracy: 0.8050\n",
            "Epoch 45/51\n",
            "188/188 - 1s - loss: 0.0808 - accuracy: 0.7982 - val_loss: 0.0803 - val_accuracy: 0.8050\n",
            "Epoch 46/51\n",
            "188/188 - 0s - loss: 0.0804 - accuracy: 0.7982 - val_loss: 0.0784 - val_accuracy: 0.8050\n",
            "Epoch 47/51\n",
            "188/188 - 0s - loss: 0.0805 - accuracy: 0.7982 - val_loss: 0.0783 - val_accuracy: 0.8050\n",
            "Epoch 48/51\n",
            "188/188 - 0s - loss: 0.0809 - accuracy: 0.7982 - val_loss: 0.0791 - val_accuracy: 0.8050\n",
            "Epoch 49/51\n",
            "188/188 - 0s - loss: 0.0804 - accuracy: 0.7982 - val_loss: 0.0788 - val_accuracy: 0.8050\n",
            "Epoch 50/51\n",
            "188/188 - 0s - loss: 0.0807 - accuracy: 0.7982 - val_loss: 0.0784 - val_accuracy: 0.8050\n",
            "Epoch 51/51\n",
            "188/188 - 1s - loss: 0.0805 - accuracy: 0.7982 - val_loss: 0.0782 - val_accuracy: 0.8050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model in training model:\n",
        "loss, acc = model.evaluate(X_train, Y_train, batch_size=128, verbose=1)\n",
        "print('Train Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Qr6gsWFTKv",
        "outputId": "29098f13-e980-4331-d03c-8f5a2ad897d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.7999\n",
            "Train Accuracy: 0.800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting training and validation accuracy to observe how the accuracy of our model improves over time:\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()\n",
        "  \n",
        "plot_metric(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "GFEzmDM5Fbs4",
        "outputId": "98d94557-3378-44ac-d513-f6b4814b424e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#By running plot_metric(history, 'loss') to plot the progress on loss:\n",
        "plot_metric(history, 'loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BFKMl72nFej0",
        "outputId": "fee2f09f-3fd0-40f4-f394-ef925f71ce3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Third Model After Optimization***"
      ],
      "metadata": {
        "id": "3Mi8h3SvG0H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initilazing the weights using Xavier normal initialization (GlorotNormal) in a layer and He Normal initialization in another and using relu as an activation function for a layer and elu for the next layer\n",
        "#and with Batch Normalization with Momentum defaults to 0.8\n",
        "#The hyperparameter  defaults to 0.001,\n",
        "#The hyperparameter  defaults to an all-zeros vector\n",
        "#The hyperparameter  defaults to an all-ones vector\n",
        "#compile the model using the optimizer Adamax with learning rate equal 0.001 and the logcosh as loss function\n",
        "#fit the model with the mini-batch Gradient Descent using 64 batches and 51 epochs\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(100, kernel_initializer='GlorotNormal', kernel_regularizer=regularizers.l2(0.01), input_shape=(n_features,), activation='relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(77, kernel_initializer='HeNormal', kernel_regularizer=regularizers.l2(0.05), activation='elu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(70, kernel_initializer='GlorotNormal', kernel_regularizer=regularizers.l2(0.09), activation='relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(70,  kernel_initializer='HeNormal', kernel_regularizer=regularizers.l2(0.11), activation='elu'))\n",
        "BatchNormalization()\n",
        "model.add(Dense(63, kernel_initializer='GlorotNormal', activation='relu'))\n",
        "BatchNormalization(\n",
        "              momentum=0.8, \n",
        "              epsilon=0.001,\n",
        "              center = True,\n",
        "              scale = True,\n",
        "              beta_initializer='zeros', \n",
        "              gamma_initializer='ones',\n",
        "              moving_mean_initializer='zeros',\n",
        "              moving_variance_initializer='ones',\n",
        "              beta_regularizer=None,\n",
        "              gamma_regularizer=None,\n",
        "              beta_constraint=None,\n",
        "              gamma_constraint=None,\n",
        "            ),\n",
        "model.add(Dense(1, activation='sigmoid', name=\"predictions\"))\n",
        "\n",
        "#compile the model using the optimizer Nadam and the categorical crossentropy as loss\n",
        "opt = Adamax(learning_rate=0.001)\n",
        "model.compile(optimizer = opt, loss='logcosh', metrics=['accuracy'])\n",
        "\n",
        "#We call model.fit() to fit our model to the training data:\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    epochs=51, \n",
        "    validation_split=0.25,\n",
        "    batch_size=64, \n",
        "    verbose=2,\n",
        "    validation_data=(X_test, Y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CPpETFoGzcf",
        "outputId": "a0461bff-14e3-48a9-9e9e-9f42913ad8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "94/94 - 1s - loss: 18.8845 - accuracy: 0.7977 - val_loss: 11.0415 - val_accuracy: 0.8050\n",
            "Epoch 2/51\n",
            "94/94 - 0s - loss: 7.2019 - accuracy: 0.7982 - val_loss: 4.3320 - val_accuracy: 0.8050\n",
            "Epoch 3/51\n",
            "94/94 - 0s - loss: 2.8435 - accuracy: 0.7982 - val_loss: 1.7168 - val_accuracy: 0.8050\n",
            "Epoch 4/51\n",
            "94/94 - 0s - loss: 1.1314 - accuracy: 0.7982 - val_loss: 0.6879 - val_accuracy: 0.8050\n",
            "Epoch 5/51\n",
            "94/94 - 0s - loss: 0.4630 - accuracy: 0.7982 - val_loss: 0.2925 - val_accuracy: 0.8050\n",
            "Epoch 6/51\n",
            "94/94 - 0s - loss: 0.2101 - accuracy: 0.7982 - val_loss: 0.1465 - val_accuracy: 0.8050\n",
            "Epoch 7/51\n",
            "94/94 - 0s - loss: 0.1188 - accuracy: 0.7982 - val_loss: 0.0956 - val_accuracy: 0.8050\n",
            "Epoch 8/51\n",
            "94/94 - 0s - loss: 0.0879 - accuracy: 0.7982 - val_loss: 0.0790 - val_accuracy: 0.8050\n",
            "Epoch 9/51\n",
            "94/94 - 0s - loss: 0.0781 - accuracy: 0.7982 - val_loss: 0.0740 - val_accuracy: 0.8050\n",
            "Epoch 10/51\n",
            "94/94 - 0s - loss: 0.0752 - accuracy: 0.7982 - val_loss: 0.0727 - val_accuracy: 0.8050\n",
            "Epoch 11/51\n",
            "94/94 - 0s - loss: 0.0745 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 12/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 13/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 14/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 15/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 16/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 17/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 18/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 19/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 20/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 21/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 22/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 23/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 24/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 25/51\n",
            "94/94 - 0s - loss: 0.0742 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 26/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 27/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 28/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 29/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 30/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 31/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 32/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 33/51\n",
            "94/94 - 0s - loss: 0.0742 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 34/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0724 - val_accuracy: 0.8050\n",
            "Epoch 35/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 36/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 37/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 38/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 39/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 40/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 41/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 42/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 43/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 44/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 45/51\n",
            "94/94 - 0s - loss: 0.0742 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 46/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 47/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 48/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 49/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0723 - val_accuracy: 0.8050\n",
            "Epoch 50/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n",
            "Epoch 51/51\n",
            "94/94 - 0s - loss: 0.0743 - accuracy: 0.7982 - val_loss: 0.0722 - val_accuracy: 0.8050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model in training model:\n",
        "loss, acc = model.evaluate(X_train, Y_train, batch_size=128, verbose=1)\n",
        "print('Train Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzVstEOFkIqN",
        "outputId": "e053fc58-eb45-4eaf-bdd7-89eeaf66595f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.7999\n",
            "Train Accuracy: 0.800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting training and validation accuracy to observe how the accuracy of our model improves over time:\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()\n",
        "  \n",
        "plot_metric(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "npGM1i7vkMMy",
        "outputId": "7beba5eb-475f-41f7-a33c-c4dfe3474da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#By running plot_metric(history, 'loss') to plot the progress on loss:\n",
        "plot_metric(history, 'loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_kXCwgpCkQmq",
        "outputId": "409f804f-8fa4-4a5f-d813-59f31de30b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}